{"meta":{"title":"高家祺的博客","subtitle":null,"description":null,"author":"高家祺","url":"https://challange.github.io","root":"/"},"pages":[{"title":"我的架构师之路——书单","date":"2019-04-13T03:37:59.732Z","updated":"2019-04-13T03:37:59.731Z","comments":true,"path":"books/index.html","permalink":"https://challange.github.io/books/index.html","excerpt":"","text":"计算机系统 深入理解计算机系统 深入理解并行编程 深入理解LINUX内核 编码，隐匿在计算机背后的语言 JAVA 码出高效Java开发手册——杨冠宝（孤尽）、高海慧（鸣莎） Mybatis从入门到精通——刘增辉 JAVA性能权威指南——Scott Oaks Java工程师修炼之道 深入理解JVM &amp; G1 GC——周明耀 Java架构师指南 Java微服务 数据结构与算法Java语言描述——Allen B.Downey 图解Java多线程设计模式——结城浩 Effective Java中文版 Spring 5 高级编程 Spring技术内幕——计文柯 Spring源码深度解析——郝佳 SpringCloud微服务实战——翟永超 深入理解SpringCloud与微服务构建——方志明 SpringBoot实战，JavaEE开发的颠覆者 深入实践SpringBoot Kafka权威指南——薛命灯 Elasticsearch源码解析与优化实战——张超 Java核心技术卷1+卷2 Java编程思想(第4版) Java8实战 Java编程的逻辑 Java并发编程的艺术 Java程序员修炼之道 Java常用算法手册 深入理解 Java 虚拟机 架构 图解性能优化 架构探险，从零开始写Java Web框架——黄勇 架构探险，轻量级微服务架构（上）——黄勇 架构探险，轻量级微服务架构（下）——黄勇 架构整洁之道——Martin，孙宇聪 大道至简——软件工程实践者的思想——周爱民 Tomcat架构解析——刘光瑞 Head First 设计模式 分布式服务架构：原理、设计与实践 人人都是架构上：分布式系统架构落地与瓶颈突破 代码整洁之道 Tomcat内核设计剖析——汪建 Head First 软件开发 从零开始学架构——李运华 软件是这样“炼“成的——从软件需求分析到软件架构设计 可伸缩服务架构：框架与中间件 大型分布式网站架构设计与实践 架构即是未来，现代企业可拓展的Web架构、流程和组织 恰如其分的软件架构 设计模式的艺术，软件开发人员内功修炼之道 系统机构，复杂系统的产品设计与开发 分布式服务框架原理与实战 重构，改善既有代码设计 数据库 Redis深度历险，核心原理与应用实践——钱文品 Sql必知必会 SQL优化核心思想 数据建模经典教程 高性能Mysql(第三版) 高性能SQL，调优精要与案例解析——闫书清 SQL学习指南 Neo4j实战 Neo4j全栈开发 图数据库 MongoDB应用设计模式 Mysql排错指南 前端 前端工程化体系设计与实践 前端架构设计 React设计模式与最佳实践——林昊 React状态管理与同构实战——侯策、颜海镜 React进阶之路 新时期的Nodejs入门 Nodejs实战 CSS世界 React学习手册 高效前端：Web高效编程与优化实践 编写可维护的JavaScript Web前端技术 Nodejs与express开发 产品 自传播：为产品注入自发传播的基因 启示录：打造用户喜爱的产品 产品设计与开发 用户故事地图 用户体验可视化指南 用户体验要素——用户为中心的产品设计 其他 C Primer Plus(第五版) 算法图解 CTO说 剑指Offer 编程珠玑 GO语言编程 GO语言学习笔记 逆流而上，阿里巴巴技术成长之路 技术之瞳，阿里巴巴技术笔试心得 明解C语言，入门篇 明解JAVA 像科学家一样思考Python 笨办法学Python Activiti实战 Activiti权威指南 工作流管理-模型、方法和系统 疯狂Workflow讲义，机遇Activiti的工作流应用开发 马云正传，活着就是为了颠覆世界 图解机器学习 图解深度学习 代码之髓 极简人工智能，你一定爱读的AI通识书 区块链技术指南 NodeJs区块链开发 Linux入门很简单 C++面向对象程序设计 Linux入门很简单 Arduino实战指南 Arduino实战案例 Arduino软硬件协同设计实战指南 美团机器学习实战 机器学习实战 机器学习系统设计 科学前沿图谱，知识可视化探索"},{"title":"分类","date":"2019-04-07T07:11:25.010Z","updated":"2019-04-07T05:50:28.000Z","comments":false,"path":"categories/index.html","permalink":"https://challange.github.io/categories/index.html","excerpt":"","text":""},{"title":"资料链接","date":"2019-04-07T07:15:22.545Z","updated":"2019-04-07T07:15:22.543Z","comments":true,"path":"links/index.html","permalink":"https://challange.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-04-07T07:13:22.859Z","updated":"2019-04-07T05:50:28.000Z","comments":false,"path":"repository/index.html","permalink":"https://challange.github.io/repository/index.html","excerpt":"","text":""},{"title":"错误信息整理","date":"2019-04-07T13:00:38.000Z","updated":"2019-05-26T05:58:54.107Z","comments":true,"path":"problem/index.html","permalink":"https://challange.github.io/problem/index.html","excerpt":"","text":"SpringCloud 1Consider defining a bean of type &apos;org.springframework.http.codec.ServerCodecConfigurer&apos; in your configuration. spring-boot-starter-web与spring-cloud-starter-gateway存在jar包冲突Spring Cloud Gateway 是使用 netty+webflux 实现因此不需要再引入 web 模块。 1java.lang.IllegalStateException: PathVariable annotation was empty on param 0. 使用Spring Cloud Feign 的时候,如果参数中带有@PathVariable形式的参数,则要用value=””标明对应的参数,否则会抛出IllegalStateException异常如：@PathVariable(value = “groupType”) String groupType 1java.lang.IllegalArgumentException: Body parameter 0 was null Spring Cloud Feign 远程调用需要携带参数，但实际上没没有携带 数据库相关 mysql排序稳定性问题 12Cause: java.sql.SQLException: Zero date value prohibitedcom.mysql.cj.core.exceptions.DataReadException: Zero date value prohibited 数据时区错误，由于数据库字段timestamp类型有时间0000-00-00 00:00:00，修改为正常时间即可。timestamp的默认值：CURRENT_TIMESTAMP（插入时个更新时间）、ON UPDATE CURRENT_TIMESTAMP（仅在更新时设置时间，插入时赋值）、CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP （创建和修改时都修改此值） 12Cause: java.sql.SQLException: Incorrect DECIMAL value: &apos;0&apos; for column &apos;&apos; at row -1; uncategorized SQLException for SQL []; SQL state [HY000]; error code [1366]; Incorrect DECIMAL value: &apos;0&apos; for column &apos;&apos; at row -1; nested exception is java.sql.SQLException: Incorrect DECIMAL value: &apos;0&apos; for column &apos;&apos; at row -1 根本解法：对数据输入严格校验，避免出现cast转换值为null的情况，或者对于null的情况从逻辑上进行控制 压测相关1Cause: java.net.NoRouteToHostException: Cannot assign requested address. 系统的连接端口耗尽 前端相关 Http ResponseHeader 中的自定义属性，如果浏览器请求抓包可以看到，但是js中获取不到，则需要检查跨域配置 解决： 响应头Access-Control-Expose-Headers，配置自定义属性，然后就可以获取到了。 问题请求：angular1.6 $http.post原文：http://www.it1352.com/886056.html参考：跨域资源共享 CORS 详解 在react中，setState是异步操作，赋值后不能马上生效。 1The value of the &apos;Access-Control-Allow-Origin&apos; header in the response must not be the wildcard &apos;*&apos; when the request&apos;s credentials mode is &apos;include&apos;. 当看到此错误时注意，当前端请求配置credentials: “include”时，后端需要配置”Access-Control-Allow-Credentials”为true，这样才能使带credentials的CORS请求成功。SpringBoot2.0下对跨域的处理方式可以为使用@CrossOrigin注解或者编写配置类实现WebMvcConfigurer接口的addCorsMappings方法。 12345678@Overridepublic void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowedHeaders(&quot;*&quot;) .allowedMethods(&quot;POST&quot;,&quot;GET&quot;) .allowedOrigins(&quot;*&quot;) .allowCredentials(true);&#125; React Eslint 报错与警告Do not use setState in componentDidMountcomponentDidMount 执行是在DOM渲染完成后，在这里面使用setState会触发重绘，相当于进行了两次渲染，因此建议在constructor或者componentWillMount中把准备工作做好。当然在componentDidMount 周期异步获取数据并通过setState赋值是正确逻辑。 Arrow function should not return assignment.1&lt;div ref=&#123;(el) =&gt; &#123; this.myCustomEl = el &#125;&#125; /&gt; 在使用箭头函数的时候，不应当返回赋值语句。 JSX props should not use arrow functionsA bind call or arrow function in a JSX prop will create a brand new function on every single render. This is bad for performance, as it may cause unnecessary re-renders if a brand new function is passed as a prop to a component that uses reference equality check on the prop to determine if it should update.https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md Expected to return a value in arrow function array-callback-return Linux及生产环境问题磁盘没有空间：Error: ENOSPC: no space left on device, write解决方案：增大磁盘空间或删除迁移没用文件，如日志文件"}],"posts":[{"title":"SpringMvc项目接入SpringCloud微服务的解决方案","slug":"微服务-SpringMvc项目接入SpringCloud微服务的解决方案","date":"2019-05-26T08:05:05.000Z","updated":"2019-05-26T07:07:08.033Z","comments":true,"path":"微服务-SpringMvc项目接入SpringCloud微服务的解决方案/","link":"","permalink":"https://challange.github.io/微服务-SpringMvc项目接入SpringCloud微服务的解决方案/","excerpt":"","text":"在SpringBoot项目大行其道的时代，仍有很多项目是基于SpringMvc，甚至是基于struts的，这些项目的特点是年代久远，项目庞大，设计文档存在缺漏。但是对于这些项目，我们不能放任不管，甚至很多项目还在为公司创造这价值。随着公司业务的发展，原先的单体项目已经不能满足快速发展变化的业务的需求，这时候就要进行微服务改造。 方案一：Sidecar异构接入 Sidecar项目可以看作老项目的影子项目，由Sidecar负责接入注册中心，并且发起远程调用和被远程调用。两个项目为一个整体对外提供服务。 优势： sidecar可以无视语言，可以用于代理古老的java项目，也可以异构代理其他语言项目，如php、python、nodejs等 sidecar可以在不对老项目进行大规模改造的情况下快速接入SpringCloud微服务，渐进式的做微服务拆分 劣势 增加项目架构和维护的复杂度，多一个项目多一个环境意味着出问题的概率又多一分 Sidecar项目配置 老项目添加HealthController 123456789101112/** * @Usage: 用于健康检查 */@RestControllerpublic class HealthController &#123; @RequestMapping(\"/openapi/health/status\") public Map status()&#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(1); map.put(\"status\",\"UP\"); return map; &#125;&#125; 新建sidecar maven项目 引入依赖 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;!-- sidecar 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-sidecar&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- eureka 注册中心--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- hystrix 熔断--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- feign 声明式服务调用--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目启动类加入如下注解 12@EnableFeignClients@EnableSidecar 不用@EnableEurekaClient，因为@EnableSidecar中包含来eureka的注册逻辑 配置文件增加sidecar、eureka、feign、hystrix、ribbon配置重点讲一下sidecar配置123456sidecar:# 配置接入web的端口port: 8080home-page-uri: http://localhost:$&#123;sidecar.port&#125;/# 配置接入web的健康检查rest接口，sidecar将请求该url，用以确定接入应用是否存活.health-uri: http://localhost:$&#123;sidecar.port&#125;/openapi/health/status 方案二：升级SpringBoot并集成SpringCloud组件一、升级SpringBoot 1.x版本在不改动Spring版本的情况下引入SrpingBoot，将项目改造为SpringBoot项目SpringBoot 1.x 引用的Spring 4.x版本，而一般SpringMvc项目也是使用Spring4.x版本，如果使用Spring更老版本或未使用spring则另当别论。 二、升级SpringBoot 2.x版本SpringBoot 2.x版本使用的是Spring5.x版本，升级2.x意味着升级spring并且需要解决spring升级带来的问题 三、引入SpringCloud并集成SpringCloud组件遇到的问题集成Eureka时，Cannot create Jersey client错误问题原因：jersey 与 fastjson 某些版本冲突导致服务无法启动错误：1Caused by: com.sun.jersey.spi.inject.Errors$ErrorMessagesException: null 解决方案：fastjson升级到 1.2.37以上版本 https://github.com/alibaba/fastjson/releases/tag/1.2.37 日期响应为linux时间戳 升级SpringBoot后，原先的日期格式化失效，在不给字段加@JsonFormat注解的情况下便要思考通过全局配置来解决 正常配置12345spring.jackson.time-zone=GMT+8# 指定响应数据格式spring.jackson.date-format=yyyy-MM-dd HH:mm:ss# 指定不返回时间戳spring.jackson.serialization.write-dates-as-timestamps=false 这样配置后并没有生效，继续查找原因。 Finally, if you opt out of the Spring Boot default MVC configuration by providing your own @EnableWebMvc configuration, you can take control completely and do everything manually by using getMessageConverters from WebMvcConfigurationSupport. 《Spring Boot Reference Guide》 去掉@EnableWebMvc后，配置可以生效。 结合WebMvcAutoConfiguration理解@EnableWebMvc","categories":[{"name":"微服务","slug":"微服务","permalink":"https://challange.github.io/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://challange.github.io/tags/微服务/"}]},{"title":"从零开始玩转SpringCloud（三）：Feign声明式服务调用","slug":"springcloud-从零开始玩转SpringCloud（三）：Feign声明式服务调用","date":"2019-05-26T04:00:30.000Z","updated":"2019-05-26T05:31:56.987Z","comments":true,"path":"springcloud-从零开始玩转SpringCloud（三）：Feign声明式服务调用/","link":"","permalink":"https://challange.github.io/springcloud-从零开始玩转SpringCloud（三）：Feign声明式服务调用/","excerpt":"","text":"Feign 概述 在开发 Spring Cloud 微服务的时候，服务之间都是以 HTTP 接口的形式对外提供服务的，因此消费者在进行调用的时候，底层就是通过 HTTP Client 的这种方式进行访问。当然我们可以使用JDK原生的 URLConnection、Apache 的 HTTP Client、Netty 异步 Http Client，Spring 的 RestTemplate 去实现服务间的调用。但是最方便、最优雅的方式是通过 Spring Cloud Open Feign 进行服务间的调用 Spring Cloud 对 Feign 进行了增强，使 Feign 支持 Spring Mvc 的注解，并整合了 Ribbon（负载均衡）、Hystrix（熔断机制） 等，从而让 Feign 更加适合SpringCloud微服务开发。 什么是 Feign Feign 是一个声明式的 Web Service 客户端。它的出现使开发 Web Service 客户端变得很简单。使用 Feign 只需要创建一个接口加上对应的注解，比如：@FeignClient 注解。 Feign 有可插拔的注解，包括 Feign 注解和 AX-RS 注解。Feign 也支持编码器和解码器，Spring Cloud Open Feign 对 Feign 进行增强支持 Spring Mvc 注解，可以像 Spring Web 一样使用 HttpMessageConverters 等。 Feign 是一种声明式、模板化的 HTTP 客户端。在 Spring Cloud 中使用 Feign，可以做到使用 HTTP 请求访问远程服务，就像调用本地方法一样的，开发者完全感知不到这是在调用远程方法，更感知不到在访问 HTTP 请求。接下来介绍一下 Feign 的特性，具体如下： 功能 可插拔的注解支持，包括 Feign 注解和AX-RS注解。 支持可插拔的 HTTP 编码器和解码器。 支持 Hystrix 和它的 Fallback。 支持 Ribbon 的负载均衡。 支持 HTTP 请求和响应的压缩。Feign 是一个声明式的 WebService 客户端，它的目的就是让 Web Service 调用更加简单。它整合了 Ribbon 和 Hystrix，从而不需要开发者针对 Feign 对其进行整合。Feign 还提供了 HTTP 请求的模板，通过编写简单的接口和注解，就可以定义好 HTTP 请求的参数、格式、地址等信息。Feign 会完全代理 HTTP 的请求，在使用过程中我们只需要依赖注入 Bean，然后调用对应的方法传递参数即可。 Feign快速使用 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 项目启动类加入如下注解： 12/** 开启 Feign 扫描支持 */@EnableFeignClients Feign 接口编写 123456789101112/** name指定微服务名称，path为类的基路径*/@FeignClient(name = \"user\", path = \"/sys/user\")public interface UserFeignSerivce &#123; /** * 插入user * * @param record * @return */ @PostMapping(\"/insertUser\") BaseResult insertUser(User record);&#125; } Feign 接口引用 1234567@Autowiredprivate UserFeignSerivce userFeignSerivce;@Overridepublic BaseResult insert(User record) &#123; return userFeignSerivce.insertUser(record);&#125; Feign 工作原理 在开发微服务应用时，我们会在主程序入口添加 @EnableFeignClients 注解开启对 Feign Client 扫描加载处理。根据 Feign Client 的开发规范，定义接口并加 @FeignClients 注解。 当程序启动时，会进行包扫描，扫描所有 @FeignClients 的注解的类，并将这些信息注入 Spring IOC 容器中。当定义的 Feign 接口中的方法被调用时，通过JDK的代理的方式，来生成具体的 RequestTemplate。当生成代理时，Feign 会为每个接口方法创建一个 RequetTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如请求参数名、请求方法等信息都是在这个过程中确定的。 然后由 RequestTemplate 生成 Request，然后把 Request 交给 Client 去处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 Http Client 也可以是 Okhttp。最后 Client 被封装到 LoadBalanceclient 类，这个类结合 Ribbon 负载均衡发起服务之间的调用。 @FeignClient 注解 name：指定 Feign Client 的名称，如果项目使用了 Ribbon，name 属性会作为微服务的名称，用于服务发现。 url：url 一般用于调试，可以手动指定 @FeignClient 调用的地址。 decode404：当发生404错误时，如果该字段为 true，会调用 decoder 进行解码，否则抛出 FeignException。 configuration：Feign 配置类，可以自定义 Feign 的 Encoder、Decoder、LogLevel、Contract。 fallback：定义容错的处理类，当调用远程接口失败或超时时，会调用对应接口的容错逻辑，fallback 指定的类必须实现 @FeignClient 标记的接口。 fallbackFactory：工厂类，用于生成 fallback 类示例，通过这个属性我们可以实现每个接口通用的容错逻辑，减少重复的代码。 path：定义当前 FeignClient 的统一前缀。 Feign 使用注意事项 使用Spring Cloud Feign，如果接口参数中带有@PathVariable路径参数,则要用value=””标明对应的参数,否则会抛出 java.lang.IllegalStateException: PathVariable annotation was empty on param 0. 异常。如：@PathVariable(value = “groupType”) String groupType 使用Spring Cloud Feign，如果接口参数中带有@RequestParam参数，@RequestParam 不能省略 在使用SpringBoot2.1.0以后版本时，多个接口的@FeignClient的name相同，场景调用同一微服务项目，但是不同模块(Controller)，可能会抛出 xx.FeignClientSpecification’, defined in null, could not be registered 异常，解决方案：增加配置spring.main.allow-bean-definition-overriding=true，但会导致@FeignClient的配置覆盖，或者手动配置FeignClient。参考文章：https://blog.csdn.net/u012211603/article/details/84312709","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/tags/SpringCloud/"},{"name":"Feign","slug":"Feign","permalink":"https://challange.github.io/tags/Feign/"}]},{"title":"Java基础学习——Lambda表达式","slug":"DIY-DIY——Lambda表达式","date":"2019-05-06T08:05:05.000Z","updated":"2019-05-08T16:09:30.086Z","comments":true,"path":"DIY-DIY——Lambda表达式/","link":"","permalink":"https://challange.github.io/DIY-DIY——Lambda表达式/","excerpt":"","text":"函数式编程是什么 函数式编程，是一种使用函数进行编程的方式，一个“函数”对应于一个数学函数:它接受零个或多个参数，生成一个或多个结果，并且不会有任何副作用，函数式函数无论在何处、何时、何地对于同样的输入总会返回相同的结果。 一、函数式编程优劣势对比匿名类与Lambda表达式代码简洁，相较于匿名内部类，Lambda表达式大大简化了代码量,代码可读性也会更好123456Runnable r1 = new Runnable()&#123; public void run()&#123; System.out.println(\"Hello\"); &#125;&#125;Runnable r2 = () -&gt; System.out.println(\"hello\"); 局限： 匿名类与lambda表达式中的this和super含义是不同的，在匿名类中，this代表自身，而lambda代表的是包含类。 匿名类可以屏蔽包含类的变量，而lambda不能，但是与包含类使用相同的变量，变量就容易产生歧义，难于理解。 123456int a = 10;Runnable r1 = () -&gt; &#123;// int a = 10; // 编译错误 int a1 = 10; System.out.println(a1);&#125;; 在涉及重载的方法，Lambda表达式可能会导致模棱两可，但可以通过强制类型转换来解决。 1234567891011121314151617interface Task &#123; public void execute();&#125; public static void doSomething(Runnable r)&#123; r.run();&#125;;public static void doSomething(Task r)&#123; r.execute();&#125;;public static void main(String[] args) &#123; // Error:(19, 9) java: 对doSomething的引用不明确 // doSomething(() -&gt; System.out.println(\"1234\")); doSomething((Task) () -&gt; System.out.println(\"1234\")); &#125; 行为参数化Lambda表达式引入了将方法作为参数传递的能力，在环绕场景下（一个方法只有中间部分逻辑不一样），增加了方法的复用，减少代码冗余。结合泛型理解，泛型使类或方法可以复用于更多的变量类型， 而函数式则进一步拓展了方法的复用性。局限： 提供行为参数化后，如果行为较为复杂，则很难一眼看出行为的含义，这时候就会降低代码的可读性，相较而言，命名规范的函数则有见名知意的好处。 无副作用纯函数，引用透明所谓共享数据就是数据可能被多个方法读取更新，在并发使用数据的时候必须通过上锁来确保线程安全。函数式编程所倡导的避免共享可变数据，只要参数确定就一定会返回确定结果，增加程序的可控性，不用考虑复杂易错的锁机制，使并行更加容易，充分利用计算机多核优势。 为了维持不可变性，“函数式”的函数或者方法都只能修改本地变量，并且它引用的对象都应是不可变对象.。 局限： 为了确保避免共享可变数据引入——增加定义变量与赋值——增大了空间的使用 异常函数式要求函数或者方法不应抛出任何异常，因为一旦抛出异常，结果就被终止了；类比于数学函数，传入一个合法的参数，一定会返回一个确定的结果。在不使用异常的情况下，Java8引入了Optional&lt; T&gt;类型来承载异常情况，如果异常不能返回结果则返回一个空的optional对象。 声明式编程经典的面向对象编程我们专注于如何实现，思维模式为：“首先做这个，紧接着更新那个，然后……”，面向对象是抽象对象、对象之间的交互；而函数式编程更关注与要做什么，Stream流是典型的应用，采用这种“要做什么”风格的编程就是声明式编程，编程者考虑的是指定规则，而由系统或者封装来觉得如何实现这个目标。这样带来的好处是让代码更加接近于问题陈述。 习惯于声明式编程思维，我们可以更容易的利用化归思想，将复杂问题拆分为若干小问题逐步解决，自顶向下，开始更加关注于函数的输入以及输出结果，而不是过早的考虑如何做、修改哪些东西。 高阶函数与科里化满足接受一个或多个函数作为参数或返回结果是一个函数的函数都是高阶函数，高阶函数提供了链式调用的功能。 科里化是一种将具备2个参数（比如，x和y）的函数f转化为使用一个参数的函数g，并且这个函数的返回值也是一个函数，它可以作为新的函数的一个参数。后者返回值与初始函数返回值，f(x,y)=(g(x))y 高阶函数与科里化也使声明式编程可以更加运用自如。 延迟计算与惰性求值延迟计算以Stream为例，向Stream发起的一系列中间操作会先被一一保存起来，直到发起一个终端操作（Stream分为中间操作和中端操作，中间操作返回一个Stream，终端操作从流水线生成结果），才会进行实际的计算。延迟计算与惰性求值使得代码具备了巨大的优化潜能。支持惰性求值的编译器会像数学家看待代数表达式那样看待函数式程序:抵消相同项从而避免执行无谓的代码，优化代码的执行顺序从而实现更高的执行效率甚至是减少错误。局限 惰性求值最大的问题还是惰性，现实世界中很多问题还是需要严格求值的，需要严格的顺序执行，如System.nextLine()每次会读取下一行记录 测试与调试 许多同学提到函数式程序难调试，个人觉得并不是因为难调试，而是我们要掌握调试的方法和工具 单元测试：因为函数式程序无副作用的特性使得单元测试更加容易，唯一需要做的就是传递一些可以代表边界条件的参数给这些函数并返回确定的结果，并且不会受其他因素干扰，如调用顺序、外部状态干扰等。Lambda没有函数名，的确带来了测试困难，这时可以借助某个字段访问Lambda函数来测试函数内封装的逻辑，可能又会问每个表达式定义一个变量做测试也太麻烦了，从声明式编程的角度出发，我们应该关注的是一个方法的可靠性，每个lambda仅仅是函数的实现细节，当放在函数内整体测试。 Java Stream Debugger工欲善其事必先利其器，推荐个调试插件Java Stream Debugger，可以以可视化的形式展现stream筛选过滤的过程。 日志输出使用peek方法可以在stream输Alt text出当前执行的元素，便于判断问题。1234567List&lt;People&gt; list = peopleList.stream() .peek(x -&gt; System.out.println(\"frist:\"+x)) .filter(item -&gt; item != null) .peek(x -&gt; System.out.println(\"second:\"+x)) .filter(item -&gt; item.getAge() &gt; 5) .peek(x -&gt; System.out.println(\"three:\"+x)) .collect(Collectors.toList()); 性能 在Java7引入了InvokeDynamic指令，用于支持在JVM上运行动态类型语言，Lambda表达式使用InvokeDynamic指令使表达式转化为字节码推迟到了运行时，避免了静态初始化，生成大量的匿名类，由此带来的问题，函数首次运行需要先进行编译，也就造成首次运行可能会占用较长时间，因此需要注意预热。 包装类型转换往往不易发现，需要重点关注 总的来说lambda不会对程序性能带来提升，甚至有可能性能下降，但是我们还是得拥抱它，因为它在多核并行计算、代码可读性、可拓展行上的优势足以抵消它降低的性能。 其他问题： 增加了使用门槛，但是工欲善其事必先利其器，作为一个合格Java程序猿本身就应具备持续的学习能力 二、Stream流的哪一个方法最有价值，为什么？ 同学们为自己心目中最有价值的Stream流方法进行了投票，投票结果来看最受欢迎的三个方法是filter、map、collect，filter主要因为可以进行条件过滤，map方法则可以映射每个元素生成新的元素，collect则是最后收集元素必不可少的一环，这三个方法无疑是Stream流操作最常用的方法。 简单讲一下流的定义：从支持数据处理的源生成的元素序列。 元素序列——流提供了可以访问特定元素类型的一组有序值的接口。流的目的在于表达计算，比如前面见到的 filter、sorted和map。 源——流会使用一个提供数据的源，如集合、数组或输入/输出资源。 数据处理操作——流的数据处理功能支持类似于数据库的操作，以及函数式编程语言中 的常用操作，如filter、map、reduce、find、match、sort等。流操作可以顺序执行，也可并行执行。 流的另外两个特点 流水线——很多流操作本身会返回一个流，这样多个操作就可以链接起来，形成一个大的流水线。流水线背后其实是一种建造者模式 内部迭代——与使用迭代器显式迭代的集合不同，流的迭代操作是在背后进行的。 流的使用一般包括三件事: 一个数据源(如集合)来执行一个查询; 一个中间操作链，形成一条流的流水线; 一个终端操作，执行流水线，并能生成结果。 parallelStream与parallel区别：parallelStream是Collection接口定义的方法，在stream构造时传入参数使用parallel生成并行流。parallel是BaseStream的一个方法，能够将一个顺序流转化为一个并行流，因此在执行parallel前可以以顺序流先进行预处理。如：123456public static long parallelSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .parallel() // 转化为并行流 .reduce(0L, Long::sum);&#125; Stream流方法的使用 参考文章：傻瓜函数式编程","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://challange.github.io/categories/Java基础/"}],"tags":[{"name":"DIY","slug":"DIY","permalink":"https://challange.github.io/tags/DIY/"},{"name":"Lambda表达式","slug":"Lambda表达式","permalink":"https://challange.github.io/tags/Lambda表达式/"},{"name":"Java基础","slug":"Java基础","permalink":"https://challange.github.io/tags/Java基础/"}]},{"title":"Git操作整理","slug":"Git-GIt操作整理","date":"2019-05-06T08:05:05.000Z","updated":"2019-05-08T16:24:18.164Z","comments":true,"path":"Git-GIt操作整理/","link":"","permalink":"https://challange.github.io/Git-GIt操作整理/","excerpt":"","text":"基础操作查看全局配置信息1git config --list 设置全局配置信息1git config --global user.name &quot;wwyz&quot; 初始化本地仓库1git init 将文件加入git版本库1git add &quot;文件名&quot; 拉取代码1git clone &quot;版本库地址&quot; &quot;目录名&quot; 查看文件状态1git status 提交代码12git commit &quot;说明&quot;git commit --amend # 重新提交 移除文件,移除后文件不在被版本控制12git rmgit rm --cached readme.txt #缓存中移除 移动文件1git mv &quot;文件路径&quot; &quot;目标文件路径&quot; 查看提交文件历史12git loggit log -p -2 #-p选项展开显示每次提交的内容差异，用-2则仅显示最近的两次更新 查看远程仓库1234567git remote -v# 添加远程仓库git remote add pb git://github.com/paulboone/ticgit.git# 拉取远程代码更新git fetch pb# 查看远程仓库的信息git remote show origin 推送提交的代码1git push origin master 忽略文件 通过在项目根目录配置.gitignore文件忽略要忽略的文件/文件夹。Java项目一般忽略：.idea、target、out、classes前端项目一般忽略：.idea、node_modules、dist .gitignore 格式规范如下： 所有空行或者以注释符号 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob(shell 所使用的简化了的正则表达式)模式匹配。 匹配模式最后跟反斜杠（/）说明要忽略的是目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 12*.[oa] # 忽略所有以 .o 或 .a 结尾的文件*~ # 忽略所有以波浪符（~）结尾的文件 Tag打标签 对某一时间点上的版本打上标签，通常结合版本使用。Git 使用的标签有两种类型：轻量级的（lightweight）和含附注的（annotated）。轻量级标签就像是个不会变化的分支，实际上它就是个指向特定提交对象的引用。而含附注标签，实际上是存储在仓库中的一个独立对象，它有自身的校验和信息，包含着标签的名字，电子邮件地址和日期，以及标签说明，标签本身也允许使用 GNU Privacy Guard (GPG) 来签署或验证。一般我们都建议使用含附注型的标签，以便保留相关信息；当然，如果只是临时性加注标签，或者不需要旁注额外信息，用轻量级标签也没问题。 列出已有标签1git tag 分支 使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。有人把 Git 的分支模型称为“必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。Git 有何特别之处呢？Git 的分支可谓是难以置信的轻量级，它的新建操作几乎可以在瞬间完成，并且在不同分支间切换起来也差不多一样快。 什么是分支 在 Git 中提交时，会保存一个提交（commit）对象，该对象包含一个指向暂存内容快照的指针，包含本次提交的作者等相关附属信息，包含零个或多个指向该提交对象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。 新建分支1git branch &quot;分支名&quot; 切换分支1git checkout &quot;分支名&quot; 合并分支12# 将其他分支合并到本分支git merge &quot;分支名&quot; 分支变基12345git rebase# 将多次提交合并为一次提交，-i表示弹出交互式的界面让用户编辑完成合并操作git rebase -i &quot;开始提交点&quot; &quot;结束提交点&quot;# 将某一段commit粘贴到另一个分支上git rebase &quot;开始提交点&quot; &quot;结束提交点&quot; --onto &quot;分支名称&quot; Git官方文档Git教程-廖雪峰","categories":[{"name":"Git","slug":"Git","permalink":"https://challange.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://challange.github.io/tags/Git/"}]},{"title":"云原生时代下的12-Factor应用原则","slug":"微服务-云原生时代下的12-Factor应用原则","date":"2019-05-06T08:05:05.000Z","updated":"2019-05-08T16:30:42.471Z","comments":true,"path":"微服务-云原生时代下的12-Factor应用原则/","link":"","permalink":"https://challange.github.io/微服务-云原生时代下的12-Factor应用原则/","excerpt":"","text":"使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。 易拓展：可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。 I. 基准代码——一份基准代码（Codebase），多份部署（deploy）12-Factor应用通常会使用版本控制系统加以管理，如Git, Mercurial, Subversion。一份用来跟踪代码所有修订版本的数据库被称作 代码库（code repository, code repo, repo）。在类似 SVN 这样的集中式版本控制系统中，基准代码 就是指控制系统中的这一份代码库；而在 Git 那样的分布式版本控制系统中，基准代码 则是指最上游的那份代码库。 一份代码库对应多份部署 基准代码和应用之间总是保持一一对应的关系： 一旦有多个基准代码，就不能称为一个应用，而是一个分布式系统。分布式系统中的每一个组件都是一个应用，每一个应用可以分别使用 12-Factor 进行开发。多个应用共享一份基准代码是有悖于 12-Factor 原则的。解决方案是将共享的代码拆分为独立的类库，然后使用 依赖管理 策略去加载它们（然而多个应用共享一份基准代码缺在很多公司很常见，特别在Two B的公司，很多公司会有定制需求）。尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份 部署 相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署。· 所有部署的基准代码相同，但每份部署可以使用其不同的版本。比如，开发人员可能有一些提交还没有同步至预发布环境；预发布环境也有一些提交没有同步至生产环境。但它们都共享一份基准代码，我们就认为它们只是相同应用的不同部署而已。 II. 依赖——显式声明依赖关系（ dependency ）大多数编程语言都会提供一个打包系统，用来为各个类库提供打包服务，就像 Perl 的 CPAN 或是 Ruby 的 Rubygems 。通过打包系统安装的类库可以是系统级的（称之为 “site packages”），或仅供某个应用程序使用，部署在相应的目录中（称之为 “vendoring” 或 “bunding”）。 12-Factor规则下的应用程序不会隐式依赖系统级的类库。 它一定通过 依赖清单 ，确切地声明所有依赖项。此外，在运行过程中通过 依赖隔离 工具来确保程序不会调用系统中存在但清单中未声明的依赖项。这一做法会统一应用到生产和开发环境。 例如， Ruby 的 Bundler 使用 Gemfile 作为依赖项声明清单，使用 bundle exec 来进行依赖隔离。Python 中则可分别使用两种工具 – Pip 用作依赖声明， Virtualenv 用作依赖隔离。甚至 C 语言也有类似工具， Autoconf 用作依赖声明，静态链接库用作依赖隔离。无论用什么工具，依赖声明和依赖隔离必须一起使用，否则无法满足 12-Factor 规范。 显式声明依赖的优点之一是为新进开发者简化了环境配置流程。新进开发者可以检出应用程序的基准代码，安装编程语言环境和它对应的依赖管理工具，只需通过一个 构建命令 来安装所有的依赖项，即可开始工作。例如，Ruby/Bundler 下使用 bundle install，而 Clojure/Leiningen 则是 lein deps。 12-Factor 应用同样不会隐式依赖某些系统工具，如 ImageMagick 或是curl。即使这些工具存在于几乎所有系统，但终究无法保证所有未来的系统都能支持应用顺利运行，或是能够和应用兼容。如果应用必须使用到某些系统工具，那么这些工具应该被包含在应用之中。 III. 配置——在环境中存储配置通常，应用的 配置 在不同 部署 (预发布、生产环境、开发环境等等)间会有很大差异。这其中包括： 数据库，Memcached，以及其他 后端服务 的配置 第三方服务的证书，如 Amazon S3、Twitter 等 每份部署特有的配置，如域名等 有些应用在代码中使用常量保存配置，这与 12-Factor 所要求的代码和配置严格分离显然大相径庭。配置文件在各部署间存在大幅差异，代码却完全一致。 判断一个应用是否正确地将配置排除在代码之外，一个简单的方法是看该应用的基准代码是否可以立刻开源，而不用担心会暴露任何敏感的信息。 需要指出的是，这里定义的“配置”并不包括应用的内部配置，比如 Rails 的 config/routes.rb，或是使用 Spring 时 代码模块间的依赖注入关系 。这类配置在不同部署间不存在差异，所以应该写入代码。 另外一个解决方法是使用配置文件，但不把它们纳入版本控制系统，就像 Rails 的 config/database.yml 。这相对于在代码中使用常量已经是长足进步，但仍然有缺点：总是会不小心将配置文件签入了代码库；配置文件的可能会分散在不同的目录，并有着不同的格式，这让找出一个地方来统一管理所有配置变的不太现实。更糟的是，这些格式通常是语言或框架特定的。 12-Factor推荐将应用的配置存储于 环境变量 中（ env vars, env ）。环境变量可以非常方便地在不同的部署间做修改，却不动一行代码；与配置文件不同，不小心把它们签入代码库的概率微乎其微；与一些传统的解决配置问题的机制（比如 Java 的属性配置文件）相比，环境变量与语言和系统无关。 配置管理的另一个方面是分组。有时应用会将配置按照特定部署进行分组（或叫做“环境”），例如Rails中的 development,test, 和 production 环境。这种方法无法轻易扩展：更多部署意味着更多新的环境，例如 staging 或 qa 。 随着项目的不断深入，开发人员可能还会添加他们自己的环境，比如 joes-staging ，这将导致各种配置组合的激增，从而给管理部署增加了很多不确定因素。 12-Factor 应用中，环境变量的粒度要足够小，且相对独立。它们永远也不会组合成一个所谓的“环境”，而是独立存在于每个部署之中。当应用程序不断扩展，需要更多种类的部署时，这种配置管理方式能够做到平滑过渡。 IV. 后端服务——把后端服务当作附加资源(backing services)后端服务是指程序运行所需要的通过网络调用的各种服务，如数据库（MySQL，CouchDB），消息/队列系统（RabbitMQ，Beanstalkd），SMTP 邮件发送服务（Postfix），以及缓存系统（Memcached）。 类似数据库的后端服务，通常由部署应用程序的系统管理员一起管理。除了本地服务之外，应用程序有可能使用了第三方发布和管理的服务。示例包括 SMTP（例如 Postmark），数据收集服务（例如 New Relic 或 Loggly），数据存储服务（如 Amazon S3），以及使用 API 访问的服务（例如 Twitter, Google Maps, Last.fm）。 12-Factor 应用不会区别对待本地或第三方服务。 对应用程序而言，两种都是附加资源，通过一个 url 或是其他存储在 配置 中的服务定位/服务证书来获取数据。12-Factor 应用的任意 部署 ，都应该可以在不进行任何代码改动的情况下，将本地 MySQL 数据库换成第三方服务（例如 Amazon RDS）。类似的，本地 SMTP 服务应该也可以和第三方 SMTP 服务（例如 Postmark ）互换。上述 2 个例子中，仅需修改配置中的资源地址。 每个不同的后端服务是一份 资源 。例如，一个 MySQL 数据库是一个资源，两个 MySQL 数据库（用来数据分区）就被当作是 2 个不同的资源。12-Factor 应用将这些数据库都视作 附加资源 ，这些资源和它们附属的部署保持松耦合。 一种部署附加4个后端服务 部署可以按需加载或卸载资源。例如，如果应用的数据库服务由于硬件问题出现异常，管理员可以从最近的备份中恢复一个数据库，卸载当前的数据库，然后加载新的数据库 – 整个过程都不需要修改代码。 V. 构建，发布，运行——严格分离构建和运行基准代码 转化为一份部署(非开发环境)需要以下三个阶段： 构建阶段 是指将代码仓库转化为可执行包的过程。构建时会使用指定版本的代码，获取和打包 依赖项，编译成二进制文件和资源文件。 发布阶段 会将构建的结果和当前部署所需 配置 相结合，并能够立刻在运行环境中投入使用。 运行阶段 （或者说“运行时”）是指针对选定的发布版本，在执行环境中启动一系列应用程序 进程。代码被构建，然后和配置结合成为发布版本 12-factor 应用严格区分构建，发布，运行这三个步骤。 举例来说，直接修改处于运行状态的代码是非常不可取的做法，因为这些修改很难再同步回构建步骤。 部署工具通常都提供了发布管理工具，最引人注目的功能是退回至较旧的发布版本。比如， Capistrano 将所有发布版本都存储在一个叫 releases 的子目录中，当前的在线版本只需映射至对应的目录即可。该工具的 rollback 命令可以很容易地实现回退版本的功能。 每一个发布版本必须对应一个唯一的发布 ID，例如可以使用发布时的时间戳（2011-04-06-20:32:17），亦或是一个增长的数字（v100）。发布的版本就像一本只能追加的账本，一旦发布就不可修改，任何的变动都应该产生一个新的发布版本。 新的代码在部署之前，需要开发人员触发构建操作。但是，运行阶段不一定需要人为触发，而是可以自动进行。如服务器重启，或是进程管理器重启了一个崩溃的进程。因此，运行阶段应该保持尽可能少的模块，这样假设半夜发生系统故障而开发人员又捉襟见肘也不会引起太大问题。构建阶段是可以相对复杂一些的，因为错误信息能够立刻展示在开发人员面前，从而得到妥善处理。 VI. 进程——以一个或多个无状态进程运行应用运行环境中，应用程序通常是以一个和多个 进程 运行的。 最简单的场景中，代码是一个独立的脚本，运行环境是开发人员自己的笔记本电脑，进程由一条命令行（例如python my_script.py）。另外一个极端情况是，复杂的应用可能会使用很多 进程类型 ，也就是零个或多个进程实例。 12-Factor 应用的进程必须无状态且无共享 。 任何需要持久化的数据都要存储在 后端服务 内，比如数据库。 内存区域或磁盘空间可以作为进程在做某种事务型操作时的缓存，例如下载一个很大的文件，对其操作并将结果写入数据库的过程。12-Factor应用根本不用考虑这些缓存的内容是不是可以保留给之后的请求来使用，这是因为应用启动了多种类型的进程，将来的请求多半会由其他进程来服务。即使在只有一个进程的情形下，先前保存的数据（内存或文件系统中）也会因为重启（如代码部署、配置更改、或运行环境将进程调度至另一个物理区域执行）而丢失。 源文件打包工具（Jammit, django-compressor） 使用文件系统来缓存编译过的源文件。12-Factor 应用更倾向于在 构建步骤 做此动作——正如 Rails资源管道 ，而不是在运行阶段。 一些互联网系统依赖于 “粘性 session”， 这是指将用户 session 中的数据缓存至某进程的内存中，并将同一用户的后续请求路由到同一个进程。粘性 session 是 12-Factor 极力反对的。Session 中的数据应该保存在诸如 Memcached 或 Redis 这样的带有过期时间的缓存中。 VII. 端口绑定——通过端口绑定提供服务互联网应用有时会运行于服务器的容器之中。例如 PHP 经常作为 Apache HTTPD 的一个模块来运行，正如 Java 运行于 Tomcat 。 12-Factor 应用完全自我加载 而不依赖于任何网络服务器就可以创建一个面向网络的服务。互联网应用 通过端口绑定来提供服务 ，并监听发送至该端口的请求。 本地环境中，开发人员通过类似 http://localhost:5000/ 的地址来访问服务。在线上环境中，请求统一发送至公共域名而后路由至绑定了端口的网络进程。 通常的实现思路是，将网络服务器类库通过 依赖声明 载入应用。例如，Python 的 Tornado, Ruby 的Thin , Java 以及其他基于 JVM 语言的 Jetty。完全由 用户端 ，确切的说应该是应用的代码，发起请求。和运行环境约定好绑定的端口即可处理这些请求。 HTTP 并不是唯一一个可以由端口绑定提供的服务。其实几乎所有服务器软件都可以通过进程绑定端口来等待请求。例如，使用 XMPP 的 ejabberd ， 以及使用 Redis 协议 的 Redis 。 还要指出的是，端口绑定这种方式也意味着一个应用可以成为另外一个应用的 后端服务 ，调用方将服务方提供的相应 URL 当作资源存入 配置 以备将来调用。 VIII. 并发——通过进程模型进行扩展任何计算机程序，一旦启动，就会生成一个或多个进程。互联网应用采用多种进程运行方式。例如，PHP 进程作为 Apache 的子进程存在，随请求按需启动。Java 进程则采取了相反的方式，在程序启动之初 JVM 就提供了一个超级进程储备了大量的系统资源(CPU 和内存)，并通过多线程实现内部的并发管理。上述 2 个例子中，进程是开发人员可以操作的最小单位。 扩展表现为运行中的进程，工作多样性表现为进程类型。 在 12-factor 应用中，进程是一等公民。12-Factor 应用的进程主要借鉴于 unix 守护进程模型 。开发人员可以运用这个模型去设计应用架构，将不同的工作分配给不同的 进程类型 。例如，HTTP 请求可以交给 web 进程来处理，而常驻的后台工作则交由 worker 进程负责。 这并不包括个别较为特殊的进程，例如通过虚拟机的线程处理并发的内部运算，或是使用诸如 EventMachine, Twisted, Node.js 的异步/事件触发模型。但一台独立的虚拟机的扩展有瓶颈（垂直扩展），所以应用程序必须可以在多台物理机器间跨进程工作。 上述进程模型会在系统急需扩展时大放异彩。 12-Factor 应用的进程所具备的无共享，水平分区的特性 意味着添加并发会变得简单而稳妥。这些进程的类型以及每个类型中进程的数量就被称作 进程构成 。 12-Factor 应用的进程 不需要守护进程 或是写入 PID 文件。相反的，应该借助操作系统的进程管理器(例如 systemd ，分布式的进程管理云平台，或是类似 Foreman 的工具)，来管理 输出流 ，响应崩溃的进程，以及处理用户触发的重启和关闭超级进程的请求。 IX. 易处理——快速启动和优雅终止可最大化健壮性12-Factor 应用的 进程 是 易处理（disposable）的，意思是说它们可以瞬间开启或停止。 这有利于快速、弹性的伸缩应用，迅速部署变化的 代码 或 配置 ，稳健的部署应用。 进程应当追求 最小启动时间 。 理想状态下，进程从敲下命令到真正启动并等待请求的时间应该只需很短的时间。更少的启动时间提供了更敏捷的 发布 以及扩展过程，此外还增加了健壮性，因为进程管理器可以在授权情形下容易的将进程搬到新的物理机器上。 进程 一旦接收 终止信号（SIGTERM） 就会优雅的终止 。就网络进程而言，优雅终止是指停止监听服务的端口，即拒绝所有新的请求，并继续执行当前已接收的请求，然后退出。此类型的进程所隐含的要求是HTTP请求大多都很短(不会超过几秒钟)，而在长时间轮询中，客户端在丢失连接后应该马上尝试重连。 对于 worker 进程来说，优雅终止是指将当前任务退回队列。例如，RabbitMQ 中，worker 可以发送一个NACK信号。 Beanstalkd 中，任务终止并退回队列会在worker断开时自动触发。有锁机制的系统诸如 Delayed Job 则需要确定释放了系统资源。此类型的进程所隐含的要求是，任务都应该 可重复执行 ， 这主要由将结果包装进事务或是使重复操作 幂等 来实现。 进程还应当在面对突然死亡时保持健壮，例如底层硬件故障。虽然这种情况比起优雅终止来说少之又少，但终究有可能发生。一种推荐的方式是使用一个健壮的后端队列，例如 Beanstalkd ，它可以在客户端断开或超时后自动退回任务。无论如何，12-Factor 应用都应该可以设计能够应对意外的、不优雅的终结。Crash-only design 将这种概念转化为 合乎逻辑的理论。 X. 开发环境与线上环境等价——尽可能的保持开发，预发布，线上环境相同从以往经验来看，开发环境（即开发人员的本地 部署）和线上环境（外部用户访问的真实部署）之间存在着很多差异。这些差异表现在以下三个方面： 时间差异： 开发人员正在编写的代码可能需要几天，几周，甚至几个月才会上线。 人员差异： 开发人员编写代码，运维人员部署代码。 工具差异： 开发人员或许使用 Nginx，SQLite，OS X，而线上环境使用 Apache，MySQL 以及 Linux。12-Factor 应用想要做到 持续部署 就必须缩小本地与线上差异。 再回头看上面所描述的三个差异: 缩小时间差异：开发人员可以几小时，甚至几分钟就部署代码。 缩小人员差异：开发人员不只要编写代码，更应该密切参与部署过程以及代码在线上的表现。 缩小工具差异：尽量保证开发环境以及线上环境的一致性。将上述总结变为一个表格如下： Item 传统应用 12-Factor 应用 每次部署间隔 数周 几个小时 开发人员 vs 运维人员 不同的人 相同的人 开发环境 vs 线上环境 不同 尽量接近 后端服务 是保持开发与线上等价的重要部分，例如数据库，队列系统，以及缓存。许多语言都提供了简化获取后端服务的类库，例如不同类型服务的 适配器 。下列表格提供了一些例子。 类型 语言 类库 适配器 数据库 Ruby/Rails ActiveRecord MySQL, PostgreSQL, SQLite 队列 Python/Django Celery RabbitMQ, Beanstalkd, Redis 缓存 Ruby/Rails ActiveSupport::Cache Memory, filesystem,Memcached 开发人员有时会觉得在本地环境中使用轻量的后端服务具有很强的吸引力，而那些更重量级的健壮的后端服务应该使用在生产环境。例如，本地使用 SQLite 线上使用 PostgreSQL；又如本地缓存在进程内存中而线上存入 Memcached。 12-Factor 应用的开发人员应该反对在不同环境间使用不同的后端服务 ，即使适配器已经可以几乎消除使用上的差异。这是因为，不同的后端服务意味着会突然出现的不兼容，从而导致测试、预发布都正常的代码在线上出现问题。这些错误会给持续部署带来阻力。从应用程序的生命周期来看，消除这种阻力需要花费很大的代价。 与此同时，轻量的本地服务也不像以前那样引人注目。借助于Homebrew，apt-get等现代的打包系统，诸如Memcached、PostgreSQL、RabbitMQ 等后端服务的安装与运行也并不复杂。此外，使用类似 Chef 和 Puppet 的声明式配置工具，结合像 Vagrant 这样轻量的虚拟环境就可以使得开发人员的本地环境与线上环境无限接近。与同步环境和持续部署所带来的益处相比，安装这些系统显然是值得的。 不同后端服务的适配器仍然是有用的，因为它们可以使移植后端服务变得简单。但应用的所有部署，这其中包括开发、预发布以及线上环境，都应该使用同一个后端服务的相同版本。 XI. 日志——把日志当作事件流日志 使得应用程序运行的动作变得透明。在基于服务器的环境中，日志通常被写在硬盘的一个文件里，但这只是一种输出格式。 日志应该是 事件流 的汇总，将所有运行中进程和后端服务的输出流按照时间顺序收集起来。尽管在回溯问题时可能需要看很多行，日志最原始的格式确实是一个事件一行。日志没有确定开始和结束，但随着应用在运行会持续的增加。 12-factor应用本身从不考虑存储自己的输出流。 不应该试图去写或者管理日志文件。相反，每一个运行的进程都会直接的标准输出（stdout）事件流。开发环境中，开发人员可以通过这些数据流，实时在终端看到应用的活动。 在预发布或线上部署中，每个进程的输出流由运行环境截获，并将其他输出流整理在一起，然后一并发送给一个或多个最终的处理程序，用于查看或是长期存档。这些存档路径对于应用来说不可见也不可配置，而是完全交给程序的运行环境管理。类似 Logplex 和 Fluentd 的开源工具可以达到这个目的。 这些事件流可以输出至文件，或者在终端实时观察。最重要的，输出流可以发送到 Splunk 这样的日志索引及分析系统，或 Hadoop/Hive 这样的通用数据存储系统。这些系统为查看应用的历史活动提供了强大而灵活的功能，包括： 找出过去一段时间特殊的事件。 图形化一个大规模的趋势，比如每分钟的请求量。 根据用户定义的条件实时触发警报，比如每分钟的报错超过某个警戒线。 XII. 管理进程——后台管理任务当作一次性进程运行进程构成（process formation）是指用来处理应用的常规业务（比如处理 web 请求）的一组进程。与此不同，开发人员经常希望执行一些管理或维护应用的一次性任务，例如： 运行数据移植（Django 中的 manage.py migrate, Rails 中的 rake db:migrate）。 运行一个控制台（也被称为 REPL shell），来执行一些代码或是针对线上数据库做一些检查。大多数语言都通过解释器提供了一个 REPL 工具（python 或 perl） ，或是其他命令（Ruby 使用 irb, Rails 使用 rails console）。 运行一些提交到代码仓库的一次性脚本。 一次性管理进程应该和正常的 常驻进程 使用同样的环境。这些管理进程和任何其他的进程一样使用相同的 代码 和 配置 ，基于某个 发布版本 运行。后台管理代码应该随其他应用程序代码一起发布，从而避免同步问题。 所有进程类型应该使用同样的 依赖隔离 技术。例如，如果Ruby的web进程使用了命令 bundle exec thin start ，那么数据库移植应使用 bundle exec rake db:migrate 。同样的，如果一个 Python 程序使用了 Virtualenv，则需要在运行 Tornado Web 服务器和任何 manage.py 管理进程时引入 bin/python 。 12-factor 尤其青睐那些提供了 REPL shell 的语言，因为那会让运行一次性脚本变得简单。在本地部署中，开发人员直接在命令行使用 shell 命令调用一次性管理进程。在线上部署中，开发人员依旧可以使用ssh或是运行环境提供的其他机制来运行这样的进程。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://challange.github.io/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://challange.github.io/tags/微服务/"}]},{"title":"Java基础学习——泛型","slug":"DIY-DIY——泛型","date":"2019-05-06T08:05:05.000Z","updated":"2019-05-26T04:04:06.164Z","comments":true,"path":"DIY-DIY——泛型/","link":"","permalink":"https://challange.github.io/DIY-DIY——泛型/","excerpt":"","text":"范型的用法 类范型，类名后面尖括号指定T或者其他名称，T只是一个代号，实例化时，指定T的具体类型 方法范型，方法名前面用尖括号指定T或者其他名称，方法参数需能推断出T的类型，调用方法时获得范型具体类型 尖括号中的范型T或其他名称只是一个指代，具体类型由实例化或者方法调用时得知 对于static的变量不能用范型 1. Java如果没有泛型会有什么灾难？泛型是参数化类型，在使用时告诉编辑器使用什么类型。 程序可控性：泛型有限定类型，泛型可以使程序执行时的类型是确定的，避免了程序的不可控性。在泛型引入之前，对于不确定类型需要使用Object，然后类型强转，此处带来的问题，Object含义不清，使代码不易懂，同时类型无界限限定，很可能会想当然使用错误类型。泛型的引入，在开发是对类或者方法的范围做一个限定，使类和方法运行在有限的类型中，使程序更清晰，可控性更强 上图是ArrayList的add操作，jdk1.5前参数为Object，也就意味着任何类型都可以放入list中。 提升复用性：解耦类或方法对类型之间的约束，通过参数化类型，使执行相同功能的方法、类能够复用代码，如果没有泛型，相同的代码每个类都要写一份，带来了大量冗余代码。一个场景，CRUD在web项目广泛使用，逻辑类似，每个类型写一遍crud方法就会造成很多冗余代码，这时可以封装一个泛型基类，一份代码给所有类型用。 使用泛型，编译时就能确保容器中插入对象的类型安全，编译器发现问题要好于运行时发现问题，运行时出问题很有可能就意味着生产事故了。我们应该避免产生隐藏较深的bug，让bug越早暴露越好。2. List&lt;? extends T&gt;和List&lt;? super T&gt;有哪些区别？ List&lt;? extends T&gt;，Get Frist适用于消费集合为主的场景，List&lt;? extends T&gt;可以赋值给任何T及T子类的场景，上界为T，put受限，add只能放入null，不能放入其他元素;使用List&lt;? extends T&gt;相当于一个视图，不具有修改能力，但被赋值的原集合修改，视图可以感知。 List&lt;? super T&gt;，Put Frist适用于生产集合为主的场景，List&lt;? super T&gt;可以赋值给任何T及T的父类集合，下界为T，put可以放入T及T的父类类型，get受限，get可以使用，但是类型会被擦除到Object。 不同点维度:赋值，put、get List&lt;? extends T&gt;类比于数据库的视图，T决定了结果集列的属性，相同与视图的List&lt;? extends T&gt;也是主要用于展示，如果要添加或者删除记录，则应修改原先的list。 3. 类名&lt;? super T&gt;存在哪些实际应用场景？（参考Comparator）Comparator&lt;? super T&gt; 准许为所有的子类使用相同的比较器。通常我们会使用Comparator自己定义对象的比较规则，如果要比较猫的重量，那么就实现猫重量的比较器，比较狗的重量，则需要实现狗重量的比较器，但如果要允许将猫与狗的重量进行比较，则就需要Comparator&lt;? super T&gt;来发挥作用，定义animal的比较器，就可以比较猫和狗的重量。&lt;? super T&gt;使的方法可以使方法不仅可以作用于父类也可以作用于子类，增加了代码的复用性。 补充泛型会擦除传入实体的属性，如果使用&lt; T &gt;，则T的类型在代码执行时会被擦除，因为Object是所有类的父类，所以此时T只具有Object的属性，但是当使用&lt; ? super T&gt;或&lt;? extends T&gt; ,定义边界，T的类型会被保留到边界T。 泛型在Java1.5引入，在泛型引入前java语言已经有了广泛的发展，较好的生态，拥有大量的类库，因此java在引入泛型的同时，也考虑到了兼容过去代码（java升级良好的兼容性我想是java能够经久不衰的重要原因）。java的泛型是具有类型擦除特性的泛型具有类型推断能力，但是类型推断仅在赋值时有效。如果将泛型方法返回结果作为参数，这时并不会执行类型推断。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://challange.github.io/categories/Java基础/"}],"tags":[{"name":"DIY","slug":"DIY","permalink":"https://challange.github.io/tags/DIY/"},{"name":"Java基础","slug":"Java基础","permalink":"https://challange.github.io/tags/Java基础/"},{"name":"泛型","slug":"泛型","permalink":"https://challange.github.io/tags/泛型/"}]},{"title":"SpringCloud——Gateway跨域配置","slug":"springcloud-SpringCloud——Gateway跨域配置","date":"2019-05-05T08:05:05.000Z","updated":"2019-05-05T08:15:10.444Z","comments":true,"path":"springcloud-SpringCloud——Gateway跨域配置/","link":"","permalink":"https://challange.github.io/springcloud-SpringCloud——Gateway跨域配置/","excerpt":"","text":"正确配置方法1234567891011121314151617181920/** * 配置跨域 * @return */@Beanpublic CorsWebFilter corsFilter() &#123; CorsConfiguration config = new CorsConfiguration(); // cookie跨域 config.setAllowCredentials(Boolean.TRUE); config.addAllowedMethod(\"*\"); config.addAllowedOrigin(\"*\"); config.addAllowedHeader(\"*\"); // 配置前端js允许访问的自定义响应头 config.addExposedHeader(\"setToken\"); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(new PathPatternParser()); source.registerCorsConfiguration(\"/**\", config); return new CorsWebFilter(source);&#125; 配置不生效方法 官方推荐配置 自定义实现GlobalFilter无效","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://challange.github.io/tags/Gateway/"}]},{"title":"SpringCloud——Gateway配置大全","slug":"springcloud-SpringCloud——Gateway配置大全","date":"2019-04-07T08:36:59.000Z","updated":"2019-04-07T08:44:25.545Z","comments":true,"path":"springcloud-SpringCloud——Gateway配置大全/","link":"","permalink":"https://challange.github.io/springcloud-SpringCloud——Gateway配置大全/","excerpt":"","text":"了解Gateway的配置才可以理解使用Gateway可以做什么事情，才能更好地应用在产品开发中。 Predicates Predicates主要起的作用是：配置路由匹配请求的规则 Http相关Path 配置对于请求路径的匹配规则 yml配置，多个参数用逗号隔开 1- Path = /aa/**,/bb/** json配置 1&#123;\"name\":\"Path\",\"args\":&#123;\"pattern\":\"/aa/**\",\"pattern1\":\"/bb/**\"&#125;&#125; Cookie 配置对Cookie中值的匹配，第一个为key，第二个为value。下例匹配cookie设置chocolate:ch.p的请求 yml配置 1- Cookie = chocolate,ch.p json配置 1&#123;\"name\":\"Cookie\",\"args\":&#123;\"_genkey_0\":\"chocolate\",\"_genkey_1\":\"ch.p\"&#125;&#125; Header 匹配Http请求中设置的内容，http-header设置X-Request-Id:\\d+可以匹配，第二个参数第二个参数是正则表达式 yml配置 1- Header = X-Request-Id,\\d+ json配置 1&#123;\"name\":\"Header\",\"args\":&#123;\"_genkey_0\":\"X-Request-Id\",\"_genkey_1\":\"\\d+\"&#125;&#125; Host 匹配Http请求Host，匹配所有host为**.somehost.com的请求 yml配置 1- Host = **.somehost.com json配置 1&#123;\"name\":\"Host\",\"args\":&#123;\"_genkey_0\":\"**.somehost.com\"&#125;&#125; Method 匹配Http请求头 yml配置 1- Method = GET json配置 1&#123;\"name\":\"Method\",\"args\":&#123;\"_genkey_0\":\"GET\"&#125;&#125; Query 匹配Http请求中的查询参数，请求中携带param1=value的请求可以匹配 yml配置 1- Query = param1,value json配置 1&#123;\"name\":\"Query\",\"args\":&#123;\"_genkey_0\":\"param1\",\"_genkey_1\":\"value\"&#125;&#125; RemoteAddr 匹配请求中的RemoteAddr yml配置 1- RemoteAddr = 192.168.1.1/24 json配置 1&#123;\"name\":\"RemoteAddr\",\"args\":&#123;\"_genkey_0\":\"192.168.1.1/24\"&#125;&#125; 时间相关After 设置时间之后可以访问 yml配置 1- After = 2017-01-20T17:42:47.789-07:00[America/Denver] json配置 1&#123;\"name\":\"After\",\"args\":&#123;\"_genkey_0\":\"2017-01-20T17:42:47.789-07:00[America/Denver]\"&#125;&#125; Before 设置时间之前可以访问 yml配置 1- Before = 2017-01-20T17:42:47.789-07:00[America/Denver] json配置 1&#123;\"name\":\"Before\",\"args\":&#123;\"_genkey_0\":\"2017-01-20T17:42:47.789-07:00[America/Denver]\"&#125;&#125; Before 设置时间段内可以访问 yml配置 1- Between = 2017-01-20T17:42:47.789-07:00[America/Denver],2017-01-21T17:42:47.789-07:00[America/Denver] json配置 1&#123;\"name\":\"Between\",\"args\":&#123;\"_genkey_0\":\"2017-01-20T17:42:47.789-07:00[America/Denver]\"，\"_genkey_1\":\"2017-01-21T17:42:47.789-07:00[America/Denver]\"&#125;&#125; 权重路由 至少两组以上路由可以配置权重路由，配置后会根据权重随机访问几个路由 yml配置 1- Weight = service1,80 json配置 1&#123;\"name\":\"Weight\",\"args\":&#123;\"_genkey_0\":\"service1\",\"_genkey_1\":\"80\"&#125;&#125; Filters路径重写 yml配置 1- RewritePath = /path/(?&lt;segment&gt;.*), /$\\&#123;segment&#125; json配置 1&#123;\"name\":\"RewritePath\",\"args\":&#123;\"_genkey_0\":\"/foo/(?&lt;segment&gt;.*)\",\"_genkey_1\":\"/$\\\\&#123;segment&#125;\"&#125;&#125; 修改请求头 yml配置 1- AddRequestHeader = X-Request-Foo,Bar json配置 1&#123;\"name\":\"AddRequestHeader\",\"args\":&#123;\"_genkey_0\":\"X-Request-Foo\",\"_genkey_1\":\"Bar\"&#125;&#125; 修改请求参数 yml配置 1- AddRequestParameter = foo,bar json配置 1&#123;\"name\":\"AddRequestParameter\",\"args\":&#123;\"_genkey_0\":\"foo\",\"_genkey_1\":\"bar\"&#125;&#125; 修改响应参数 yml配置 1- AddResponseHeader = X-Request-Foo,Bar json配置 1&#123;\"name\":\"AddResponseHeader\",\"args\":&#123;\"_genkey_0\":\"X-Request-Foo\",\"_genkey_1\":\"Bar\"&#125;&#125; 路径前缀增强 请求路径/hello, 将会被替换为 /mypath/hello yml配置 1- PrefixPath = /mypath json配置 1&#123;\"name\":\"PrefixPath\",\"args\":&#123;\"_genkey_0\":\"/mypath\"&#125;&#125; 路径前缀删除 请求/name/bar/foo，去除掉前面两个前缀之后，最后转发到目标服务的路径为/foo yml配置 1- StripPrefix = 2 json配置 1&#123;\"name\":\"StripPrefix\",\"args\":&#123;\"_genkey_0\":\"2\"&#125;&#125; 请求携带保留原始Host yml配置 1- PreserveHostHeader json配置 1&#123;\"name\":\"PreserveHostHeader\",\"args\":&#123;&#125;&#125; 重定向 yml配置 1- RedirectTo = 302,http://acme.org json配置 1&#123;\"name\":\"RedirectTo\",\"args\":&#123;\"_genkey_0\":\"302\",\"_genkey_1\":\"http://acme.org\"&#125;&#125; 断路器 yml配置 12345- name: Hystrix args: # 断路后跳转地址 name: fallbackcmd fallbackUri: forward:/incaseoffailureusethis json配置 1&#123;\"name\":\"Hystrix\",\"args\":&#123;\"name\":\"fallbackcmd\",\"fallbackUri\":\"forward:/incaseoffailureusethis\"&#125;&#125; 集成Redis原生支持请求限流 yml配置 1234- name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 10 redis-rate-limiter.burstCapacity: 20 json配置 1&#123;\"name\":\"RequestRateLimiter\",\"args\":&#123;\"redis-rate-limiter.replenishRate\":\"10\",\"redis-rate-limiter.burstCapacity\":\"20\"&#125;&#125; 删除请求头属性 yml配置 1- RemoveRequestHeader = X-Request-Foo json配置 1&#123;\"name\":\"RemoveRequestHeader\",\"args\":&#123;\"_genkey_0\":\"X-Request-Foo\"&#125;&#125; 删除响应头属性 yml配置 1- RemoveResponseHeader = X-Request-Foo json配置 1&#123;\"name\":\"RemoveResponseHeader\",\"args\":&#123;\"_genkey_0\":\"X-Request-Foo\"&#125;&#125; 重写响应头 将请求 /42?user=ford&amp;password=omg!what&amp;flag=true, 改为 /42?user=ford&amp;password=***&amp;flag=true yml配置 1- RewriteResponseHeader = X-Response-Foo,password=[^&amp;]+,password=*** json配置 1&#123;\"name\":\"RewriteResponseHeader\",\"args\":&#123;\"_genkey_0\":\"X-Response-Foo\",\"_genkey_1\":\"password=[^&amp;]+\",\"_genkey_2\":\"password=***\"&#125;&#125; 重设请求路径 请求/foo/bar，在接下来的处理中被改为/bar yml配置 1- SetPath =/&#123;segment&#125; json配置 1&#123;\"name\":\"SetPath\",\"args\":&#123;\"_genkey_0\":\"/&#123;segment&#125;\"&#125;&#125; 设置响应头 在接下来的处理中修改响应头X-Response-Foo为Bar yml配置 1- SetResponseHeader =X-Request-Foo,Bar json配置 1&#123;\"name\":\"SetResponseHeader\",\"args\":&#123;\"_genkey_0\":\"X-Response-Foo\",\"_genkey_1\":\"Bar\"&#125;&#125; 设置Http状态 yml配置 123- name: SetStatus args: status: 401 json配置 1&#123;\"name\":\"SetStatus\",\"args\":&#123;\"_genkey_0\":\"302\"&#125;&#125; 设置文件传输大小 yml配置 123- name: RequestSize args: maxSize: 5000000 json配置 1&#123;\"name\":\"RequestSize\",\"args\":&#123;\"_genkey_0\":\"5000000\"&#125;&#125; 失败重试 yml配置1234- name: Retry args: retries: 3 statuses: BAD_GATEWAY","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://challange.github.io/tags/Gateway/"}]},{"title":"从零开始玩转SpringCloud（二）：Gateway网关对接注册中心","slug":"springcloud-从零开始玩转SpringCloud（二）：Gateway网关对接注册中心","date":"2019-04-07T06:54:30.000Z","updated":"2019-04-07T06:58:46.810Z","comments":true,"path":"springcloud-从零开始玩转SpringCloud（二）：Gateway网关对接注册中心/","link":"","permalink":"https://challange.github.io/springcloud-从零开始玩转SpringCloud（二）：Gateway网关对接注册中心/","excerpt":"","text":"简介：Spring Cloud Gateway旨在为微服务架构提供一种简单而有效的统一的API路由管理方式。 项目搭建 引入依赖12345678910&lt;!--Eureka 客户端--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--Gateway 路由--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt; 注意：不要引入spring-boot-starter-web包，会导致Gateway启动抛出异常，错误如下。因为Spring Cloud Gateway 是使用 netty+webflux实现，webflux与web是冲突的。1Consider defining a bean of type &apos;org.springframework.http.codec.ServerCodecConfigurer&apos; in your configuration. 在Application中使用@EnableEurekaClient 12345678910111213package com.example.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@EnableEurekaClient@SpringBootApplicationpublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class, args); &#125;&#125; 配置自动将注册中心的服务映射为路由 12345678910111213141516171819server: port: 8081spring: application: name: gateway cloud: gateway: # 此处配置表示开启自动映射Eureka下发的路由 discovery: locator: enabled: true lowerCaseServiceId: trueeureka: client: # Eureka Server地址 service-url: defaultZone: http://localhost:8760/eureka/ 至此，已经可以直接通过gateway访问其他注册在Eureka中的服务的接口了。如客户端接口地址：http://localhost:8080/test，注册名称为client，则访问地址为http://localhost:8081/client/test。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://challange.github.io/tags/Gateway/"}]},{"title":"从零开始玩转SpringCloud（一）：Eureka注册中心","slug":"springcloud-从零开始玩转SpringCloud（一）：Eureka注册中心","date":"2019-04-07T06:50:20.000Z","updated":"2019-04-07T08:53:50.341Z","comments":true,"path":"springcloud-从零开始玩转SpringCloud（一）：Eureka注册中心/","link":"","permalink":"https://challange.github.io/springcloud-从零开始玩转SpringCloud（一）：Eureka注册中心/","excerpt":"","text":"Eureka 介绍：Eureka，古希腊词语，含义为我找到了，我发现了！相传阿基米德发现福利原理时说出了这个词。 Eureka是Spring Cloud Netflix微服务套件中的一部分，可以与Springboot构建的微服务很容易的整合起来。Eureka包含了服务器端和客户端组件。服务器端，也被称作是服务注册中心，用于提供服务的注册与发现。Eureka支持高可用的配置，当集群中有分片出现故障时，Eureka就会转入自动保护模式，它允许分片故障期间继续提供服务的发现和注册，当故障分片恢复正常时，集群中其他分片会把他们的状态再次同步回来。客户端组件包含服务消费者与服务生产者。在应用程序运行时，Eureka客户端向注册中心注册自身提供的服务并周期性的发送心跳来更新它的服务租约。同时也可以从服务端查询当前注册的服务信息并把他们缓存到本地并周期性的刷新服务状态。 Eureka-Server服务搭建 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 在Application中使用@EnableEurekaServer 12345678910111213package com.example.eureka;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@EnableEurekaServer@SpringBootApplicationpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 配置文件 1234567891011121314151617181920212223242526spring: application: name: eureka-server # cAPP名称，在Eureka注册名称 profiles: active: peer eureka: instance: hostname: peer # 服务注册中心实例的主机名 client: register-with-eureka: false # 是否注册自己 fetch-registry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ server: enableSelfPreservation: false #关闭自我保护机制logging: level: com: netflix: eureka: info discovery: infoserver: port: 8760 至此一个Eureka-Server就搭建好了。 Eureka-Server服务高可用 说到高可用，就是要保证一个节点挂掉，不会影响整个系统的运行。解决办法就是多部署几个实例，搭建集群，那么一个实例节点挂掉，其他实例仍可提供服务。 新建三个配置文件application-peer1.yml、application-peer2.yml、application-peer3， 123456789101112131415161718192021222324spring: application: name: eureka-server profiles: active: peer1eureka: instance: hostname: peer1 #服务注册中心实例的主机名 client: serviceUrl: # 另外几个注册中心地址 defaultZone: http://localhost:8762/eureka, http://localhost:8763/eureka server: enableSelfPreservation: false #关闭自我保护logging: level: com: netflix: eureka: info discovery: infoserver: port: 8761 123456789101112131415161718192021222324spring: application: name: eureka-server profiles: active: peer2eureka: instance: hostname: peer2 #服务注册中心实例的主机名 client: serviceUrl: # 另外几个注册中心地址 defaultZone: http://localhost:8761/eureka, http://localhost:8763/eureka server: enableSelfPreservation: false #关闭自我保护logging: level: com: netflix: eureka: info discovery: info server: port: 8762 123456789101112131415161718192021222324spring: application: name: eureka-server profiles: active: peer3eureka: instance: hostname: peer3 #服务注册中心实例的主机名 client: serviceUrl: # 另外几个注册中心地址 defaultZone: http://localhost:8761/eureka, http://localhost:8762/eureka server: enableSelfPreservation: false #关闭自我保护logging: level: com: netflix: eureka: info discovery: infoserver: port: 8763 idea下按配置文件启动多个项目，Active profiles指定启动配置文件。分别启动刚刚写好的三个配置文件即可。 生产环境下是否需要动态配置注册中心，目前的配置对生产环境动态配置非常不友好 客户端配置 引入Eureka Client依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 在Application中使用@EnableEurekaServer 12345678910111213package com.example.eureka;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@EnableEurekaClient@SpringBootApplicationpublic class EurekaClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientApplication.class, args); &#125;&#125; 配置文件 12345678910111213spring: application: name: gateway # 在eureka-server注册名称 eureka: client: service-url: defaultZone: http://localhost:8760/eureka/ # #高可用配置# defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/,http://localhost:8763/eureka/ server: port: 8081 至此已EurekaClient已经搭建成功","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://challange.github.io/tags/SpringCloud/"},{"name":"Eureka","slug":"Eureka","permalink":"https://challange.github.io/tags/Eureka/"}]},{"title":"Scratch3.0——作品保存","slug":"scratch-Scratch3-0——作品保存","date":"2019-04-06T08:46:31.000Z","updated":"2019-05-26T04:08:23.809Z","comments":true,"path":"scratch-Scratch3-0——作品保存/","link":"","permalink":"https://challange.github.io/scratch-Scratch3-0——作品保存/","excerpt":"","text":"整体思路概述作品结构分析服务端设计前端设计","categories":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/categories/Scratch/"}],"tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/tags/Scratch/"}]},{"title":"Java字节码分析i=i++的结果","slug":"Java基础-Java字节码分析i-i-的结果","date":"2019-02-16T08:46:31.000Z","updated":"2019-05-26T05:53:12.765Z","comments":true,"path":"Java基础-Java字节码分析i-i-的结果/","link":"","permalink":"https://challange.github.io/Java基础-Java字节码分析i-i-的结果/","excerpt":"","text":"示例代码12345public static void main(String[] args) &#123; int i =3; i=i++; System.out.println(i);&#125; 运行结果是3，不是4，接下来就探索一下原因 分析 关键还是对i++即 IINC 1 1的理解。i++是直接在局部变量表上做自加操作。而i=i+1是先从局部变量表拷贝i的值到操作栈，在操作栈执行i+1操作，最后将操作栈的运算结果写入局部变量表，从这个角度也体现了i++的运算效率更高。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://challange.github.io/categories/Java基础/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://challange.github.io/tags/Java基础/"}]},{"title":"蚂蚁金服分布式事务框架","slug":"微服务-蚂蚁金服分布式事务框架","date":"2019-01-31T08:05:05.000Z","updated":"2019-05-26T05:52:43.750Z","comments":true,"path":"微服务-蚂蚁金服分布式事务框架/","link":"","permalink":"https://challange.github.io/微服务-蚂蚁金服分布式事务框架/","excerpt":"","text":"分布式事务基本术语 术语 描述 事务 事务是指作为单个逻辑工作单元执行的一系列操作，要么完全执行，要么完全不执行。 分布式事务 事务的发起者、资源及资源管理器和事务协调者分别位于不同的分布式系统的不同节点之上。 分支事务 一个分布式事务可能包含多个数据库本地事务，在分布式事务框架下，分支事务可能是一个分库上执行的 SQL 语句，或是一个自定义模式服务的调用。 发起方 分布式事务的发起方负责启动分布式事务，通过调用参与者的服务，将参与者纳入到分布式事务当中，并决定整个分布式事务是提交还是回滚。一个分布式事务有且只能有一个发起方。 参与者 参与者提供分支事务服务。当一个参与者被发起方调用，则被纳入到该发起方启动的分布式事务中，成为该分布式事务的一个分支事务。一个分布式事务可以有多个参与者。 事务管理器 事务管理器是一个独立的服务，用于协调分布式事务，包括创建主事务记录、分支事务记录，并根据分布式事务的状态，调用参与者提交或回滚方法。 主事务记录 又叫 Activity 记录，是整个分布式事务的主体。其最核心的数据结构是事务号（TX_ID）和事务状态（STATE），它是在启动分布式事务时持久化写入数据库的，它的状态决定了这个分布式事务的状态。 分支事务记录 又叫 Action 记录，用于标识分支事务。它记录了该提供该分支事务的参与者的信息，其中包括参与者的唯一标识等。通过分支事务信息，事务管理器就可以对参与者进行提交或者回滚操作。 最终一致 事务处理过程中，会有短暂不一致的情况，但通过恢复系统，可以让事务的数据达到最终一致的目标。 解决问题分布式事务解决三大核心问题：跨数据库、跨服务以及混合分布式事务。 跨数据库分布式事务当业务规模增大，单库单表无法满足业务需求时，自然就会出现分库分表的情况。但是，单机事务又不能保证分库后的事务属性，分布式事务几乎无法避免。分布式事务可以让应用轻松具备跨库分布式事务处理能力，像使用单机数据库事务一样，透明地使用分布式事务。 跨服务的分布式事务在基于 SOA（Service-Oriented Architecture，面向服务架构）的分布式应用环境下，系统按照功能解耦，拆分成不同的微服务，一项业务往往会涉及多个服务之间的调用。因此，为了保障业务完整，需要保证各调用服务间的数据一致性。分布式事务同样支持跨服务的分布式事务，并且可以很方便的与 SOFABoot、Spring Cloud、Dubbo 等框架打通，实现业务链路级别的分布式事务。 混合分布式事务在一个大规模的分布式应用环境下，除了常见的微服务、数据库资源之外，还会涉及到消息队列、缓存等系统资源的使用。同时，依然需要保证这些资源间访问的数据的一致性。分布式事务支持在同一个分布式事务中引入数据库、服务、消息队列等不同类型的资源，并且支持混合接入模式。 角色简介分布式事务主要涉及三个角色，发起方、参与者与事务管理器，具体描述如下： 发起方：分布式事务的发起方负责启动分布式事务，通过调用参与者的服务，将参与者纳入到分布式事务当中，并决定整个分布式事务是提交还是回滚。一个分布式事务有且只能有一个发起方。 参与者：参与者提供分支事务服务。当一个参与者被发起方调用后，该参与者会被纳入到该发起方启动的分布式事务中，成为该分布式事务的一个分支事务。一个分布式事务可以有多个参与者。 事务管理器：事务管理器是一个独立的服务，用于协调分布式事务，包括创建主事务记录、分支事务记录，并根据分布式事务的状态，调用参与者提交或回滚方法。 事务执行状态说明分布式事务使用两阶段提交协议（Two-Phase Commit Protocol，简称 2PC）来保证事务执行的原子性。2PC 包含两个阶段： 第一阶段，也称准备阶段。由事务发起者向各参与者发送请求，询问参与者是否准备好执行事务。第二阶段，也称提交阶段。在一阶段所有参与者都确认可以执行事务后，各参与者开始分别执行事务分支。所有分支都成功则事务数据提交成功，否则，所有分支都进行数据回滚操作。事务在某一时间点可能处在以下状态之一： 初始化：应用发起事务 进行中 准备中：一阶段操作中 提交中：一阶段结束，正在二阶段的提交操作中 回滚中：一阶段结束，因为某些业务失败，正在二阶段的回滚操作中 已结束 已提交：事务结束，事务执行的数据变更已提交 已回滚：事务结束，事务执行的数据变更已回滚 异常 提交异常：一阶段结束，二阶段处理提交操作时出现异常 回滚异常：一阶段结束，二阶段处理回滚操作时出现异常 回查异常：一阶段结束，二阶段处理回查业务接口时出现异常 分布式事务中的二阶段提交是什么？ 二阶段提交协议（Two-phase Commit Protocol，简称 2PC）是分布式事务的核心协议。在此协议中，一个事务管理器（Transaction Manager，简称 TM）协调 1 个或多个资源管理器（Resource Manager，简称 RM）的活动，所有资源管理器向事务管理器汇报自身活动状态，由事务管理器根据各资源管理器汇报的状态（完成准备或准备失败）来决定各资源管理器是“提交”事务还是进行“回滚”操作。 二阶段提交的具体流程如下： 应用程序向事务管理器提交请求，发起分布式事务； 在第一阶段，事务管理器联络所有资源管理器，通知它们准备提交事务； 各资源管理器返回完成准备（或准备失败）的消息给事务管理器（响应超时算作失败）； 在第二阶段： 如果所有资源管理器均完成准备（如图 1），则事务管理器会通知所有资源管理器执行事务提交； 如果任一资源管理器准备失败（如图 2 中的资源管理器 B），则事务管理器会通知所有资源管理器进行事务回滚。 分布式事务中的 TCC 模型Try-Confirm-Cancel（TCC）是初步操作（Try）、确认操作（Confirm）和取消操作（Cancel）三种操作的缩写，这三种操作的业务含义如下： Try 阶段：对业务系统做检测及资源预留； Confirm 阶段：对业务系统做确认提交。默认 Confirm 阶段是不会出错的，只要 Try 成功，Confirm 一定成功； Cancel 阶段：当业务执行出现错误，需要回滚的状态下，执行业务取消，释放预留资源。 TCC 是二阶段提交协议（Two-phase Commit Protocol，简称 2PC）的扩展，Try 操作对应 2PC 中一阶段的准备提交事务（Prepare），Confirm 对应 2PC 中二阶段事务提交（Commit），Cancel 对应 2PC 中二阶段事务回滚（Rollback）。 与 2PC 不同的是，TCC 是一种编程模型，是应用层的 2PC；TCC 的 3 个操作均由编码实现，通过编码实现了 2PC 资源管理器的功能。 TCC 自编码的特性决定 TCC 资源管理器可以跨数据库、跨应用实现资源管理，将对不同的数据库访问、不同的业务操作通过编码方式转换一个原子操作，解决了复杂业务场景下的事务问题。同时 TCC 的每一个操作对于数据库来讲都是一个本地数据库事务，操作结束则本地数据库事务结束，数据库的资源也就被释放；这就规避了数据库层面的 2PC 对资源占用导致的性能低下问题。 柔性事务的定义与分类柔性事务的定义刚性事务（如单数据库）完全遵循 ACID 规范，即数据库事务正确执行的四个基本要素： 原子性（Atomicity） 一致性（Consistency） 隔离性（Isolation） 持久性（Durability） 柔性事务（如分布式事务）为了满足可用性、性能与降级服务的需要，降低一致性（Consistency）与隔离性（Isolation）的要求，遵循 BASE 理论： 基本业务可用性（Basic Availability） 柔性状态（Soft state） 最终一致性（Eventual consistency） 同样的，柔性事务也部分遵循 ACID 规范：原子性：严格遵循一致性：事务完成后的一致性严格遵循；事务中的一致性可适当放宽隔离性：并行事务间不可影响；事务中间结果可见性允许安全放宽持久性：严格遵循 柔性事务的分类柔性事务分为：两阶段型、补偿型、异步确保型、最大努力通知型。 两阶段型分布式事务二阶段提交，对应技术上的 XA、JTA/JTS，这是分布式环境下事务处理的典型模式。 补偿型TCC 型事务（Try-Confirm-Cancel）可以归为补偿型。在 Try 成功的情况下，如果事务要回滚，Cancel 将作为一个补偿机制，回滚 Try 操作；TCC 各操作事务本地化，且尽早提交（没有两阶段约束）；当全局事务要求回滚时，通过另一个本地事务实现“补偿”行为。TCC 是将资源层的二阶段提交协议转换到业务层，成为业务模型中的一部分。 异步确保型将一些有同步冲突的事务操作变为异步操作，避免对数据库事务的争用，如消息事务机制。 最大努力通知型通过通知服务器（消息通知）进行，允许失败，有补充机制。 问题 有没有可能在回滚时已经时过境迁，回滚前该记录已经发生了很多次改变，那么如何应对？在update之前，会先把账户的金额保存下来，执行update操作，然后把执行之后的金额保存下来。因为在二阶段有可能会是回滚操作，回滚的时候如果想把执行之前的数据覆盖回去的话，必须要保证在覆盖的那个时刻，这些行上面的数据没有被别人变更过，所以最后会加一个逻辑行锁，这个就是金融系统的特性需求。 参考资料XTS支付宝分布式事务学习指南大规模SOA系统中的分布式事务处理_程立_SD2C2008支付宝运营架构中柔性事务指的是什么？分布式事务：蚂蚁金服核心金融场景下的演进","categories":[{"name":"微服务","slug":"微服务","permalink":"https://challange.github.io/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://challange.github.io/tags/微服务/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://challange.github.io/tags/分布式事务/"}]},{"title":"SQL调优的基本公式(转)","slug":"数据库-SQL调优的基本公式","date":"2019-01-29T08:05:05.000Z","updated":"2019-05-26T05:54:21.366Z","comments":true,"path":"数据库-SQL调优的基本公式/","link":"","permalink":"https://challange.github.io/数据库-SQL调优的基本公式/","excerpt":"","text":"SQL的优化是DBA日常工作中不可缺少的一部分，记得在学生时期，曾经在ITPUB上看到一篇帖子，当时楼主在介绍SQL优化的时候，用一个公式来讲解他在做sql优化的时候遵循的原则： T=S/V(T代表时间，S代表路程，V代表速度) S指SQL所需访问的资源总量，V指SQL单位时间所能访问的资源量，T自然就是SQL执行所需时间了;我们为了获得SQL最快的执行时间，可以根据公式定义上去反推： 在S不变的情况下，我们可以提升V来降低T：通过适当的索引调整，我们可以将大量的速度较慢的随机IO转换为速度较快的顺序IO；通过提升服务器的内存，使得将更多的数据放到内存中，会比数据放到磁盘上会得到明显的速度提升；采用电子存储介质进行数据存储和读取的SSD，突破了传统机械硬盘的性能瓶颈，使其拥有极高的存储性能;在提升V上我们可以采用较高配置的硬件来完成速度的提升； 在V不变的情况下，我们可以减小S来降低T：这是SQL优化中非常核心的一个环节，在减小S环节上，DBA可以做的可以有很多，通常可以在查询条件中建立适当的索引，来避免全表扫描；有时候可以改写SQl，添加一些适当的提示符，来改变SQL的执行计划，使SQL以最少的扫描路径完成查询；当这些方法都使用完了之后，你是否还有其他方案来优化喃？在阿里系的DBA职位描述中有条就是要求DBA需要深入的了解业务，当DBA深入的了解业务之后，这个时候能站在业务上，又站DB角度上考虑，这个时候在去做优化，有时候能达到事半功倍的效果。 案例一：通过降低S，来提升T 原理介绍：我们知道B+索引叶子节点的值是按照索引字段升序的，比如我们对（nick，appkey）两个字段做了索引，那么在索引中的则是按照nick，appkey的升序排列；如果我们现在的一条sql：select count(distinct nick) from xxxx_nickapp_09_29;用于查询统计某天日志表中的UV，优化器选择了该表上索引ind_nick_appkey（nick，appkey）来完成查询，则开始从nick1开始一条条扫描下来，直到扫描到最后一个nick_n,那么中间过程会扫描很多重复的nick（最左边普通扫描），如果我们能够跳过中间重复的nick，则性能会优化非常多（最右边的松散扫描）： 从上面的可以得到一个结论： 如果这条统计uv的sql能够按照右边的loose index scan的方式来扫描话，会大大的减小我们上面提到的S；所以需要通过改写sql来达到伪loose index scan：（MySql优化器不能直接的对count(distinct column)做优化） root@DB 09:41:30&gt;select count(*) from ( select distinct(nick) from xxxx_nickapp_09_29) t ; +———-+| count(*) |+———-+| 806934 |+———-+Sql内查询中先选出不同的nick，最后在外面套一层count，就可以得到nick的distinct值总和；最重要的是在子查询中：select distinct(nick) 实现了上图中的伪loose index scan，优化器在这个时候的执行计划为Using index for group-by ，这样mysql就把distinct优化为group by，首先利用索引来分组，然后扫描索引，对需要的nick只扫描一条记录。 真实案例： 该案例选自我们的一个线上的生产系统，该系统每天有大量的日志数据入库，单表的容量在10G-50G之间，然后做汇总分析，计算日志数据中的uv就是其中一个逻辑，sql如下：1select count(distinct nick) from xxxx_nickapp_09_29; 即使在_xxxx分表上加上nick的索引，通过查看执行计划，为全索引扫描，由于单表的数据量过大，sql在执行的时候，会对整个服务器带来抖动，需要对原来的SQL进行改写，使其支持loose index scan； 优化前： root@DB 09:41:30&gt;select count(distinct nick) from xxxx_nickapp_09_29;+———-+| count(*) |+———-+| 806934 | 1 row in set (52.78 sec)执行一次sql需要花费52.78s 优化后： root@DB 09:41:30&gt;select count(*) from ( select distinct(nick) from xxxx_nickapp_09_29)t ; +———-+| count(*) |+———-+| 806934 |+———-+1 row in set (5.81 sec) 由52.78秒降至5.81秒，速度提升了差不多10倍； 查看SQL的执行计划： 优化写法： root@DB 09:41:30&gt;explain select count(*) from ( select distinct(nick) from xxxx_nickapp_09_29)t ;| id | select_type | table |type |possible_keys|key|key_len|ref|rows|Extra|| :——– | ——–:| ——–:| ——–:| ——–:| ——–:| ——–:| ——–:| ——–:|:–: || 1 | SIMPLE | xxxx_nickapp_09_29 |range|NULL|ind_nick_appkey|67|NULL|2124695|Using index for group-by|原始写法：root@DB 09:41:50&gt;explain select count(distinct nick) from xxxx_nickapp_09_29;| id | select_type | table |type |possible_keys|key|key_len|ref|rows|Extra|| :——– | ——–:| ——–:| ——–:| ——–:| ——–:| ——–:| ——–:| ——–:|:–: || 1 | SIMPLE | xxxx_nickapp_09_29 |index|NULL|ind_nick_appkey|177|NULL|19546123|Using index| 可以看到我们的路程由19546123减小到2124695，减小了9倍多. 案例二：结合业务递增的写入特点，巧妙优化UV统计count(*) 有时候觉得，优化一条sql的最高境界就是让这sql能够从把这条从系统中拿掉，不管怎样，这些都是建立在你足够的了解业务上，就能够推动一些业务产品的升级或者下线，这样的DBA你能做到吗？ 下面看一个案例：应用每天都会对入库的分表统计一个总数：select count() from xx_01_01;随着单表的数据量越来越大（单表在20G左右），每次进行count的时候，速度越来越慢，同时需要扫描较多的数据页块，导致整个数据库性能的抖动，通过分析业务的特点，由于每张表采用自增id的方式进行插入，并且没有数据的删除，所以统计全表的总数就可以变通一下：所以这条sql：select count() from xx_01_01;可以变通为： select max(id)-min(id)+1 from xx_01_01;执行速度可以得到质的飞跃. 案例三：通过提升V，来降低T—随机IO VS 顺序IO真实线上案例：在我们的一个核心产品库上，承载着非常大量的随机读，就叫它读库好了。一天读库的load非常的高，通过慢日志发现，有一条sql频繁的出现在慢日中，这条sql的查询条件很复杂，同时该表上的类似相同的索引也非常的多，当时是怀疑索引走错，通过explain 来查看SQL的执行计划：发现执行计划中的using where代表查询回表了，同时由于回表的记录rows较大，所以带来了大量的随机IO： 所以我们只需要在原来的索引冗余掉is_detail字段就可以通过覆盖索引的方法优化掉该sql，避免了查询回表而导致的随机io，用顺序io替换了原来的随机io，SQL的执行速度得到极大提升：（下图会去掉is_detail字段的测试） 总结：SQL优化是很有趣的一件事情，我们在日常工作中可以按照t=s/v的思路来进行优化，也许你第一次运用它的时候有些陌生，但是只要不断的练习，善于总结，你也会发现其中的规律，真是妙哉妙哉。还有一点很重要的是，你的SQL优化不要脱离实际业务，也许你在哪里优化一条sql花了1个小时，但是去和开发同学讨论优化成果的时候，开发同学说这条sql其实可以下线了，那时候真的哭笑不得了 . 原文：玄惭http://hidba.org/?p=498","categories":[{"name":"数据库","slug":"数据库","permalink":"https://challange.github.io/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://challange.github.io/tags/数据库/"},{"name":"SQL调优","slug":"SQL调优","permalink":"https://challange.github.io/tags/SQL调优/"}]},{"title":"毕玄：我在阿里的十年技术感悟(转)","slug":"程序人生-毕玄：我在阿里的十年技术感悟","date":"2019-01-29T08:05:05.000Z","updated":"2019-05-26T05:56:41.317Z","comments":true,"path":"程序人生-毕玄：我在阿里的十年技术感悟/","link":"","permalink":"https://challange.github.io/程序人生-毕玄：我在阿里的十年技术感悟/","excerpt":"","text":"从业余程序员到职业程序员程序员刚入行时，我觉得最重要的是把自己培养成职业的程序员，我的程序员起步比同龄人都晚了很多，更不用说现在的年轻人了，我大学读的是生物专业，在上大学前基本算是完全没接触过计算机，军训的时候因为很无聊，我和室友每天跑去学校的机房玩，我现在还印象很深刻，我第一次走进机房的时候，别人问，你是要玩windows，还是dos，我那是完全的一抹黑，后来就只记得在机房一堆人都是在练习盲打，军训完，盲打倒是练的差不多了，对计算机就这么产生了浓厚的兴趣，大一的时候都是玩组装机，捣鼓了一些，对计算机的硬件有了那么一些了解。 到大二后，买了一些书开始学习当时最火的网页三剑客，学会了手写HTML、PS的基本玩法之类的，课余、暑假也能开始给人做做网站什么的(ps: 那个时候做网站真的好赚钱)，可能那样过了个一年左右，做静态的网页就不好赚钱了，也不好找实习工作，于是就开始学asp，写些简单的CRUD，做做留言板、论坛这些动态程序，应该算是在这个阶段接触编程了。 毕业后加入了深圳的一家做政府行业软件的公司，一个非常靠谱和给我空间的Leader，使得自己在那几年有了不错的成长，终于成了一个职业的程序员，通常来说，业余或半职业的程序员，多数是1个人，或者很小的一个团队一起开发，使得在开发流程、协作工具（例如jira、cvs/svn/git等）、测试上通常会有很大的欠缺，而职业的程序员在这方面则会专业很多，另外，通常，职业的程序员做的系统都要运行较长的时间，所以在可维护性上会特别注意，这点我是在加入阿里后理解更深的，一个运行10年的系统，和一个写来玩玩的系统显然是有非常大差别的。 这块自己感觉也很难讲清楚，只能说模模糊糊有个这样的概念，通常在有兴趣的基础上，从业余程序员跨越到成为职业程序员我觉得不会太难。 编程能力的成长作为程序员，最重要的能力始终是编程能力，就我自己的感受而言，我觉得编程能力的成长主要有这么几个部分。 编程能力初级：会用编程，首先都是从学习编程语言的基本知识学起的，不论是什么编程语言，有很多共同的基本知识，例如怎么写第一个Hello World、if/while/for、变量等，因此我比较建议在刚刚开始学一门编程语言的时候，还是就看看编程语言自己的一些文档就好，而不要上来就去看一些高阶的书，我当年学Java的时候上来就看Think in Java、Effective Java之类的，真心好难懂。 除了看文档以外，编程是个超级实践的活，所以一定要多写代码，只有这样才能真正熟练起来，这也是为什么我还是觉得在面试的时候让面试者手写代码是很重要的，这个过程是非常容易判断写代码的熟悉程度的，很多人会说由于写代码都是高度依赖IDE的，导致手写很难，但我绝对相信写代码写了很多的人，手写一段不是太复杂的可运行的代码是不难的，即使像我这种三年多没写过代码的人，让我现在手写一段不太复杂的可运行的Java程序，还是没问题的，前面N年的写代码生涯使得很多东西已经深入骨髓了。 我觉得编程能力初级这个阶段对于大部分程序员来说都不会是问题，勤学苦练，是这个阶段的核心。 编程能力中级：会查和避免问题除了初级要掌握的会熟练的使用编程语言去解决问题外，中级我觉得首先是提升查问题的能力。 在写代码的过程中，出问题是非常正常的，怎么去有效且高效的排查问题，是程序员群体中通常能感受到的大家在编程能力上最大的差距，解决问题能力强的基本很容易在程序员群体里得到很高的认可，在查问题的能力上，首先要掌握的是一些基本的调试技巧，好用的调试工具，就像在Java里JDK自带的jstat、jmap、jinfo，不在JDK里的mat、gperf、btrace等，工欲善其事必先利其器，在查问题上是非常典型的，有些时候大家在查问题时的能力差距，有可能仅仅是因为别人比你多知道一个工具而已，除了调试技巧和工具外，查问题的更高境界会和编程能力的高级阶段有非常大的关系，就是懂原理，一个懂原理的程序员在查问题的水平上是有明显差距的，我想很多的同学应该能感受到，有些时候查出问题的原因仅仅是因为有效的工具，知其然不知其所以然，我给很多阿里的同学培训过Java排查问题的方法，在这个培训里，我经常也会讲到查问题的能力的培养最主要的也是熟练，多尝试给自己写一些会出问题的程序，多积极的看别人是怎么查问题的，多积极的去参与排查问题，很多最后查问题能力强的人多数仅仅是因为“无他，但手熟尔”。 就像我自己，排查问题能力的提升主要是在2009年和2010年，那两年作为淘宝消防队（处理各种问题和故障的虚拟团队）的成员处理了很多的故障和问题，当时消防队还有阿里最公认的技术大神多隆，向他学习到了很多排查问题的技巧，和他比，我排查问题的能力就是初级的那种，我印象最深刻的是有一次我们一起查一个应用cpu us高的问题，我们两定位到是一段代码在某种输入参数的时候会造成cpu us高的原因后，我能想到的继续查的方法是去生产环境抓输入参数，然后再用参数来本地debug看是什么原因，但多隆在看了一会那段代码后，给了我一个输入参数，我拿这个参数一运行，果然cpu us很高，哎，而且这种case不是一次两次，所以我经常和别人说，我是需要有问题场景才能排查出问题的，但多隆是完全有可能直接看代码就能看出问题的，这是本质的差距。 除了查问题外，更厉害的程序员是在写代码的过程就会很好的去避免问题，大家最容易理解的就是在写代码时处理各种异常情况，但这里通常也是程序员们很大的差距的地方，写一段正向逻辑的代码，大部分情况下即使有差距，也不会太大，但在怎么很好的处理这个过程中有可能出现的异常上，这个时候的功力差距会非常明显，很多时候一段代码里处理异常逻辑的部分都会超过正常逻辑的代码量，我经常说，一个优秀程序员和普通程序员的差距，很多时候压根就不需要看什么满天飞的架构图，而只用show一小段的代码就可以，举一个小case大家感受下，当年有一个严重故障，最后查出的原因是输入的参数里有一个是数组，把这个数组里的值作为参数去查数据库，结果前面输入了一个很大的数组，导致从数据库查了大量的数据，内存溢出了，很多程序员现在看都会明白对入参、出参的保护check，但类似这样的case在我自己排查问题的经历了真的碰到了好多。 在中级这个阶段，我会推荐大家尽可能的多刻意的去培养下自己这两个方面的能力，成为一个能写出高质量代码、有效排查问题的优秀程序员。 编程能力高级：懂高级API和原理就我自己的经历而言，我是在写了多年的Java代码后，才开始真正更细致的学习和掌握Java的一些更高级的API，我相信多数Java程序员也是如此，我算是从2003年开始用Java写商业系统的代码，但直到在2007年加入淘宝后，才开始非常认真的学习Java的IO通信、并发这些部分的API，尽管以前也学过也写过一些这样的代码，但完全就是皮毛，当然，这些通常来说有很大部分的原因会是工作的相关性，多数的写业务系统的程序员可能基本就不需要用到这些，所以导致会很难懂这些相对高级一些的API，但这些API对真正的理解一门编程语言我觉得至关重要，在之前的程序员成长路线的文章里我也讲到了这个部分，在没有场景的情况下，只能靠自己去创造场景来学习好，我觉得只要有足够的兴趣，这个问题还是不大的，毕竟现在有各种开源，这些是可以非常好的帮助自己创造机会学习的，例如学Java NIO，可以自己基于NIO包一个框架，然后对比Netty，看看哪些写的是不如Netty的，这样会非常有助于真正的理解。 在学习高级API的过程中，以及排查问题的过程中，我自己越来越明白懂编程语言的运行原理是非常重要的，因此我到了后面的阶段开始学习Java的编译机制、内存管理、线程机制等，对于我这种非科班出身的而言，学这些会因为缺乏基础更难很多，但这些更原理性的东西学会了后，对自己的编程能力会有质的提升，包括以后学习其他编程语言的能力，学这些原理最好的方法我觉得是先看看一些讲相关知识的书，然后去翻看源码，这样才能真正的更好的掌握，最后是在以后写代码的过程中、查问题的过程中多结合掌握的原理，才能做到即使在N年后也不会忘。 在编程能力的成长上，我觉得没什么捷径，非常赞同1万小时理论，在中级、高级阶段如果有人指点或和优秀的程序员们共事，会好非常多，不过我觉得这个和读书也有点像，到了一定阶段后（例如高中），天分会成为最重要的分水岭，不过就和大部分行业一样，大部分的情况下都还没到拼天分的时候，只需要拼勤奋就好。 系统设计能力的成长除了少数程序员会进入专深的领域，例如Linux Kernel、JVM，其他多数的程序员除了编程能力的成长外，也会越来越需要在系统设计能力上成长。 通常一个编程能力不错的程序员，在一定阶段后就会开始承担一个模块的工作，进而承担一个子系统、系统、跨多领域的更大系统等。 我自己在工作的第三年开始承担一个流程引擎的设计和实现工作，算是一个不算小的系统，并且也是当时那个项目里的核心部分，那个阶段学会了一些系统设计的基本知识，例如需要想清楚整个系统的目标、模块的划分和职责、关键的对象设计等，而不是上来就开始写代码，但那个时候由于我是一个人写整个系统，所以其实对设计的感觉并还没有那么强力的感觉。 第三段经历，是做阿里电商的异地多活，这对我来说是真正的去做一个巨大系统的架构师，尽管我以前做HSF的时候参与了淘宝电商2.0-3.0的重大技术改造，但参与和自己主导是有很大区别的，这个架构改造涉及到了阿里电商众多不同专业领域的技术团队，在这个阶段，我学会的最主要的： 1). 子系统职责划分，在这种超大的技术方案中，很容易出现某些部分的职责重叠和冲突，这个时候怎么去划分子系统，就非常重要了，作为大架构师，这个时候要从团队的职责、团队的可持续性上去选择团队； 2). 大架构师最主要的职责是控制系统风险，对于这种超大系统，一定是多个专业领域的架构师和大架构师共同设计，怎么确保在执行的过程中对于系统而言最重要的风险能够被控制住，这是我真正的理解什么叫系统设计文档里设计原则的部分，设计原则我自己觉得就是用来确保各个子系统在设计时都会遵循和考虑的，一定不能是虚的东西，例如在异地多活架构里，最重要的是如何控制数据风险，这个需要在原则里写上，最基本的原则是可接受系统不可用，但也要保障数据一致，而我看过更多的系统设计里设计原则只是写写的，或者千篇一律的，设计原则切实的体现了架构师对目标的理解（例如当时异地多活这个其实开始只是个概念，但做到什么程度才叫做到异地多活，这是需要解读的，也要确保在技术层面的设计上是达到了目标的），技术方案层面上的选择原则，并确保在细节的设计方案里有对于设计原则的承接以及执行； 3). 考虑问题的全面性，像异地多活这种大架构改造，涉及业务层面、各种基础技术层面、基础设施层面，对于执行节奏的决定要综合考虑人力投入、机器成本、基础设施布局诉求、稳定性控制等，这会比只是做一个小的系统的设计复杂非常多。 系统设计能力的成长，我自己觉得最重要的一是先在一两个技术领域做到专业，然后尽量扩大自己的知识广度，例如除了自己的代码部分外，还应该知道具体是怎么部署的，部署到哪去了，部署的环境具体是怎么样的，和整个系统的关系是什么样的，像我自己，是在加入基础设施团队后才更加明白有些时候软件上做的一个决策，会导致基础设施上巨大的硬件、网络或机房的投入，但其实有可能只需要在软件上做些调整就可以避免，做做研发、做做运维可能是比较好的把知识广度扩大的方法，第二点是练习自己做tradeoff的能力，这个比较难，做tradeoff这事需要综合各种因素做选择，但这也是所有的架构师最关键的，可以回头反思下自己在做各种系统设计时做出的tradeoff是什么，这个最好是亲身经历，听一些有经验的架构师分享他们选择背后的逻辑也会很有帮助，尤其是如果恰好你也在同样的挑战阶段，光听最终的架构结果其实大多数时候帮助有限。 技术Leader我觉得最好是能在架构师的基础上，后续注重成长的方面还是有挺大差别，就不在这篇里写了，后面再专门来写一篇。 程序员金字塔我认为程序员的价值关键体现在作品上，被打上作品标签是一种很大的荣幸，作品影响程度的大小我觉得决定了金字塔的层次，所以我会这么去理解程序员的金字塔。 在那之后的几年也负责过一些系统，但总体感觉好像在系统设计上的成长没那么多，直到在阿里的经历，才敢上自己在系统设计上有了越来越多的体会（References里有一篇我在系统设计上犯过的14个错，可以看到我走的一堆的弯路），在阿里有一次做分享，讲到我在系统设计能力方面的成长，主要是因为三段经历，负责专业领域系统的设计 -&gt; 负责跨专业领域的专业系统的设计 -&gt; 负责阿里电商系统架构级改造的设计。 第一段经历，是我负责HSF，HSF是一个从0开始打造的系统，它主要是作为支撑服务化的框架，是个非常专业领域的系统，放在整个淘宝电商的大系统来看，其实它就是一个很小的子系统，这段经历里让我最深刻的有三点： 1). 要设计好这种非常专业领域的系统，专业的知识深度是非常重要的，我在最早设计HSF的几个框的时候，是没有设计好服务消费者/提供者要怎么和现有框架结合的，在设计负载均衡这个部分也反复了几次，这个主要是因为自己当时对这个领域掌握不深的原因造成的; 2). 太技术化，在HSF的阶段，出于情怀，在有一个版本里投入了非常大的精力去引进OSGi以及去做动态化，这个后来事实证明是个非常非常错误的决定，从这个点我才真正明白在设计系统时一定要想清楚目标，而目标很重要的是和公司发展阶段结合； 3). 可持续性，作为一个要在生产环境持续运行很多年的系统而言，怎么样让其在未来更可持续的发展，这个对设计阶段来说至关重要，这里最low的例子是最早设计HSF协议的时候，协议头里竟然没有版本号，导致后来升级都特别复杂，最典型的例子是HSF在早期缺乏了缺乏了服务Tracing这方面的设计，导致后面发现了这个地方非常重要后，全部落地花了长达几年的时间，又例如HSF早期缺乏Filter Chain的设计，导致很多扩展、定制化做起来非常不方便。 第二段经历，是做T4，T4是基于LXC的阿里的容器，它和HSF的不同是，它其实是一个跨多领域的系统，包括了单机上的容器引擎，容器管理系统，容器管理系统对外提供API，其他系统或用户通过这个来管理容器，这个系统发展过程也是各种犯错，犯错的主要原因也是因为领域掌握不深，在做T4的日子里，学会到的最重要的是怎么去设计这种跨多个专业领域的系统，怎么更好的划分模块的职责，设计交互逻辑，这段经历对我自己更为重要的意义是我有了做更大一些系统的架构的信心。 当然，要打造一款作品，仅有上面的两点能力是不够的，作品里很重要的一点是对业务、技术趋势的判断，希望作为程序员的大伙，都能有机会打造一款世界级的作品，去为技术圈的发展做出贡献。 由于目前IT技术更新速度还是很快的，程序员这个行当是特别需要学习能力的，我一直认为，只有对程序员这个职业真正的充满兴趣，保持自驱，才有可能在这个职业上做好，否则的话是很容易淘汰的。 本文转自毕玄老师个人公众号：hellojavacases","categories":[{"name":"程序人生","slug":"程序人生","permalink":"https://challange.github.io/categories/程序人生/"}],"tags":[{"name":"程序人生","slug":"程序人生","permalink":"https://challange.github.io/tags/程序人生/"}]},{"title":"Scratch3.0——作品截图","slug":"scratch-Scratch3-0——作品截图","date":"2019-01-23T08:46:31.000Z","updated":"2019-05-26T06:06:02.399Z","comments":true,"path":"scratch-Scratch3-0——作品截图/","link":"","permalink":"https://challange.github.io/scratch-Scratch3-0——作品截图/","excerpt":"","text":"Scratch 的舞台是基于canvas，最初尝试直接通过canvas的dom，然后生成图片，但最后只能得到一个黑色的图片，得到黑色图片的原因是没有取到有效的canvas而不是因为图片跨域，当初在这里走了很多弯路，继续研究舞台组件stage.jsx，从vm.renderer可以获取canvas，于是通过这个canvas对象生成图片，记得当时的效果是偶尔会得到有效图片，但是大部分时候依然是黑色的图片，原因稍后回解释。为了实现截图，当时又进一步研究了renderer的代码，最后找到了draw方法，通过多次尝试发现在draw方法的最后执行canvas对象生成图片可以获得舞台的有效图片。 最初的笨办法在node_modules中找到scratch-render/src/RenderWebGL.js中的draw方法，也可以直接在dist中修改编译后的文件。顺便解释一下draw是对舞台进行了清理和重新绘制，而draw的频率非常频繁，因此不能直接通过canvas获取图片。在重绘后追加获取图片的toDataURL方法，考虑到需要在gui里面调用，此处采用了监听键盘事件来通信，接收到截图请求将舞台图片放在window.sessionStorage内存中，在需要使用的时候可以直接从sessionStorage获得。123456789101112131415161718192021draw () &#123; this._doExitDrawRegion(); // 获取gl const gl = this._gl; // twgl.bindFramebufferInfo(gl, null); gl.viewport(0, 0, gl.canvas.width, gl.canvas.height); gl.clearColor.apply(gl, this._backgroundColor); gl.clear(gl.COLOR_BUFFER_BIT); // 重新绘制 this._drawThese(this._drawList, ShaderManager.DRAW_MODE.default, this._projection); // 增加如下代码 let img = new Image(); img.src = gl.canvas.toDataURL('image/png',0.7) document.onkeydown = function (e) &#123; if(e.keyCode == 16)&#123; window.sessionStorage.setItem(\"coverImg\",img.src) console.log('webGL') &#125; &#125; &#125; 带来问题 直接修改node_modules依赖的内容，严重影响团队开发、项目部署，提升了项目维护的复杂度。 每次draw都会执行toDataURL方法，并且赋值，增大了系统开销。 通过事件映射，提升了项目的复杂度。 优化回归最初问题的本源，不能直接从canvas.toDataURL获得舞台截图的原因是执行toDataURL的时候可能正好draw在重绘。因此先截图前先draw然后获取图片。123this.renderer.draw();const img = new Image();img.src = this.canvas.toDataURL('image/png', 0.7); 码猿Scratch学习平台：https://scratch.imayuan.com","categories":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/categories/Scratch/"}],"tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/tags/Scratch/"}]},{"title":"Scratch3.0——克隆代码仓库的正确姿势","slug":"scratch-Scratch3-0——克隆代码仓库的正确姿势","date":"2019-01-23T08:46:31.000Z","updated":"2019-05-26T06:06:02.395Z","comments":true,"path":"scratch-Scratch3-0——克隆代码仓库的正确姿势/","link":"","permalink":"https://challange.github.io/scratch-Scratch3-0——克隆代码仓库的正确姿势/","excerpt":"","text":"对Scratch3.0进行二次开发，首先要在github上fock官方代码，但是在自己开发的同时又要跟进官方的代码就要在git做如下配置。 步骤：1、配置上游项目地址。即将你 fork 的项目的地址给配置到自己的项目上。使用以下命令来配置。1➜ git remote add upstream https://github.com/LLK/scratch-gui.git 然后可以查看一下配置状况，很好，上游项目的地址已经被加进来了。12345➜ git remote -vorigin https://github.com/***/scratch-gui.git (fetch)origin https://github.com/***/scratch-gui.git (push)upstream https://github.com/LLK/scratch-gui.git (fetch)upstream https://github.com/LLK/scratch-gui.git (push) 2、获取上游(官方)项目更新。使用 fetch 命令更新，fetch 后会被存储在一个本地分支 upstream/master 上。如果长时间没有更新，可能会非常慢，一定要在网络环境好的情况下更新或从GitHub下载代码。1➜ git fetch upstream 3、合并到本地分支。切换到 master 分支，合并 upstream/master 分支。1➜ git merge upstream/master 如果提示： fatal: refusing to merge unrelated histories，这是因为本地和远端已经是两个独立的版本库，git认为是不相干的版本库。1➜ git merge upstream/master --allow-unrelated-histories 4、合并冲突。因为是在原先代码的基础上二次开发，冲突不可避免，而最费时间的也是这里解决冲突这一步。 5、提交推送。根据自己情况提交推送自己项目的代码。1➜ git push origin master 由于项目已经配置了上游项目的地址，所以如果 fork 的项目再次更新，重复步骤 2、3、4即可。 留几个问题供大家思考交流： 冲突在所难免，在开发中注意什么可以更快更高效的解决冲突合并代码？ 如果官方代码重构了某部分模块，你的代码严重依赖该模块该如何处理？ 如果需要修改开源系统，不要改动原系统，而是要开发辅助系统。（——从零开始学架构） 码猿Scratch学习平台：https://scratch.imayuan.com","categories":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/categories/Scratch/"}],"tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/tags/Scratch/"}]},{"title":"Scratch3.0——项目层次结构","slug":"scratch-Scratch3-0——项目层次结构","date":"2019-01-23T08:46:31.000Z","updated":"2019-05-26T06:06:02.385Z","comments":true,"path":"scratch-Scratch3-0——项目层次结构/","link":"","permalink":"https://challange.github.io/scratch-Scratch3-0——项目层次结构/","excerpt":"","text":"简要介绍: 本文旨在介绍scratch3.0项目层次结构及关键功能。源码：https://github.com/LLK/scratch-gui 核心依赖库scratch-audio：声音拓展scratch-blocks：代码积木块scratch-l10n：国际化scratch-paint：绘图拓展scratch-render：舞台渲染，在舞台区域出现的基于WebGL的处理器。scratch-storage：作品存储加载scratch-svg-renderer：svg处理scratch-vm：虚拟机，管理状态并执行业务逻辑。 Scratch-Gui目录结构在scratch中最为核心的便是gui库，目录结构如下：123456789101112131415161718192021222324├── build # 默认编译后的文件夹│ ├── static # 静态资源│ ├── index.html │ ├── gui.js │ ├── lib.js # 编译后主要的js文件 ├── src│ ├── components # UI组件，负责页面呈现│ ├── containers # 容器组件，承载容器组件业务逻辑│ ├── css # 全局通用css│ ├── examples # 集成测试用例│ ├── extensions # 拓展案例│ ├── lib # 插件及高阶组件│ ├── audio # 声音插件│ ├── backpack # 背包插件│ ├── default-project # 默认项目│ ├── libraries # 素材库相关│ ├── video # 视频模块│ ├── playground # 编译后页面的模版│ ├── reducers # 全局状态控制├── test # 测试用例├── translations # 翻译库├── README.md└── package.json└── webpack.consig.js 码猿Scratch学习平台：https://scratch.imayuan.com","categories":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/categories/Scratch/"}],"tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://challange.github.io/tags/Scratch/"}]},{"title":"前端关于SEO与使用注意","slug":"前端-前端关于SEO与使用注意","date":"2018-09-28T08:05:05.000Z","updated":"2019-05-26T06:03:12.790Z","comments":true,"path":"前端-前端关于SEO与使用注意/","link":"","permalink":"https://challange.github.io/前端-前端关于SEO与使用注意/","excerpt":"","text":"原则：前端页面要尽可能提高页面在搜索引擎的曝光度 优先使用语义化的html标签，因为语义化的标签对搜索更友好 网页title命名，首页放对于网站最重要的一句话——网站名称，子页面命名为：页面名 - 网站名，如： scratch作品列表 - 码猿网（使用scratch因为scratch搜索频率更高，可增加网站的曝光的概率）；火影忍者 - 码猿网（增加通过作品名搜索曝光的可能性）。title的长度在20～30字之间 关键词标签：。标签能够让搜索引擎更加迅速的识别网站内容。不同标签以英文逗号隔开，书写必须规范，否则会被搜索引擎降权。 description，对于网页的介绍，100字以内。 seo相关属性，整个网站可配置默认，但最好不同页面，title，keywords，description不完全一样，并表达出页面要突出的特点。 超链接标签：a。A标签主要的作用是加链接，因此不要给A标签写过多的样式，也不要让A标签包过多的内容，内容越多核心词的权重将会瓜分干净。 代码模版123456789101112131415161718&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;&lt;title&gt;title&lt;/title&gt;&lt;meta name=&quot;keywords&quot; content=&quot;***,***,***,***,***,***&quot;&gt;&lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;robots&quot; content=&quot;ALL&quot; /&gt;&lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;revisit-after&quot; CONTENT=&quot;3 days&quot; &gt;&lt;meta name=&quot;copyright&quot; content=&quot;Copyright 2017&quot; /&gt;&lt;meta name=&quot;subject&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;application-name&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;msapplication-tooltip&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;language&quot; content=&quot;zh-CN&quot; /&gt;&lt;meta name=&quot;owner&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;url&quot; content=&quot;&quot; /&gt;&lt;meta name=&quot;identifier-URL&quot; content=&quot;&quot; /&gt;&lt;link rel=&quot;icon&quot; href=&quot;img/icon32.ico&quot; /&gt;","categories":[{"name":"前端","slug":"前端","permalink":"https://challange.github.io/categories/前端/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://challange.github.io/tags/前端/"}]}]}